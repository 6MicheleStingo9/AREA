<!--
    Jinja2 Template for AI Risk Analysis Report
-->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Risk Analysis Report</title>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <style>
/* Base Styles - Reset, Layout, Typography */

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
    line-height: 1.6;
    color: #1F2937;
    background: #F9FAFB;
}

.container {
    max-width: 1400px;
    margin: 0 auto;
    padding: 20px;
}

header {
    background: linear-gradient(135deg, #667EEA 0%, #764BA2 100%);
    color: white;
    padding: 40px 20px;
    border-radius: 12px;
    margin-bottom: 30px;
    box-shadow: 0 10px 40px rgba(0,0,0,0.1);
}

header h1 {
    font-size: 2.5rem;
    margin-bottom: 10px;
    font-weight: 700;
}

header .subtitle {
    font-size: 1.1rem;
    opacity: 0.95;
    font-weight: 300;
}

.metadata {
    background: rgba(255,255,255,0.2);
    padding: 15px;
    border-radius: 8px;
    margin-top: 20px;
    display: flex;
    gap: 30px;
    flex-wrap: wrap;
}

.metadata-item {
    display: flex;
    align-items: center;
    gap: 8px;
}

.metadata-item strong {
    font-weight: 600;
}

.section {
    background: white;
    padding: 30px;
    border-radius: 12px;
    margin-bottom: 30px;
    box-shadow: 0 4px 20px rgba(0,0,0,0.08);
}

.section h2 {
    font-size: 1.8rem;
    margin-bottom: 20px;
    color: #111827;
    border-bottom: 3px solid #667EEA;
    padding-bottom: 10px;
}

.section h3 {
    font-size: 1.4rem;
    margin-top: 25px;
    margin-bottom: 15px;
    color: #374151;
}

.grid-3 {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 20px;
}

.grid-2 {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 25px;
    margin-bottom: 30px;
}

footer {
    text-align: center;
    padding: 30px;
    color: #6B7280;
    font-size: 0.9rem;
    border-top: 1px solid #E5E7EB;
    margin-top: 50px;
}

@media (max-width: 768px) {
    .grid-3 {
        grid-template-columns: 1fr;
    }
    .grid-2 {
        grid-template-columns: 1fr;
    }
    header h1 {
        font-size: 1.8rem;
    }
}

/* Cards for questionnaire Q&A */
.qa-card {
    background: #F3F4F6;
    border: 2px solid #CBD5E1;
    border-radius: 12px;
    padding: 18px 22px 12px 22px;
    margin-bottom: 18px;
    box-shadow: 0 2px 8px rgba(100,116,139,0.07);
}
/* Components - Cards, Badges, Filters, Tree */

.risk-badge {
    display: inline-block;
    padding: 8px 16px;
    border-radius: 20px;
    font-weight: 600;
    font-size: 1.1rem;
    text-transform: uppercase;
}

/* Metadata description box under header */
.metadata-description {
    margin-top: 10px;
    padding: 10px 12px;
    background: #F8FAFC;
    border: 1px solid #E6EEF6;
    border-radius: 8px;
}
.meta-desc-text {
    margin: 0;
    color: #374151;
    font-size: 0.95rem;
    line-height: 1.4;
}
.meta-desc-text.small {
    font-size: 0.85rem;
    color: #6B7280;
}
.metadata-description a {
    color: #1E40AF;
    text-decoration: underline;
}

/* Executive Summary box style */

.executive-summary p {
    margin: 0;
    color: #000000;
    line-height: 1.6;
    font-size: 1.2em;
}



/* Report header actions: title, download link, source link, taxonomy versions */
.report-meta-actions {
    display: flex;
    flex-direction: column;
    gap: 8px;
    margin-top: 12px;
}
.report-meta-actions .report-title {
    font-size: 1.05rem;
    font-weight: 700;
    color: #0F172A;
}
.report-meta-actions .report-links {
    display: flex;
    gap: 12px;
    align-items: center;
}
.meta-link {
    display: inline-block;
    padding: 8px 14px;
    background: linear-gradient(180deg, #0369A1 0%, #075985 100%);
    color: #FFFFFF;
    border-radius: 10px;
    text-decoration: none;
    font-weight: 600;
    font-size: 0.95rem;
    border: 1px solid rgba(3,105,161,0.12);
    box-shadow: 0 6px 18px rgba(3,105,161,0.08);
    transition: transform 0.12s ease, box-shadow 0.12s ease, opacity 0.12s ease;
}
.meta-link:hover {
    transform: translateY(-2px);
    box-shadow: 0 10px 24px rgba(3,105,161,0.12);
    opacity: 0.98;
}
.meta-link.secondary {
    background: #FFFFFF;
    color: #075985;
    border: 1px solid #D1E8F6;
    box-shadow: none;
}
.meta-link.secondary:hover {
    transform: translateY(-2px);
}
.taxonomy-versions {
    margin-top: 6px;
    font-size: 0.9rem;
    color: #374151;
}
.taxonomy-versions .taxonomy-item {
    background: #F3F4F6;
    border: 1px solid #E6E9EE;
    padding: 4px 8px;
    border-radius: 6px;
    margin-right: 6px;
}

.risk-badge.critical {
    background: #DC2626;
    color: white;
}

.risk-badge.high {
    background: #F59E0B;
    color: white;
}

.risk-badge.medium {
    background: #10B981;
    color: white;
}

.risk-badge.low {
    background: #3B82F6;
    color: white;
}

.stat-card {
    background: linear-gradient(135deg, #667EEA 0%, #764BA2 100%);
    color: white;
    padding: 25px;
    border-radius: 12px;
    text-align: center;
    box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
}

.stat-card .value {
    font-size: 3rem;
    font-weight: 700;
    margin-bottom: 10px;
}

.stat-card .label {
    font-size: 1rem;
    opacity: 0.9;
    text-transform: uppercase;
    letter-spacing: 1px;
}

.badge {
    display: inline-block;
    padding: 4px 12px;
    border-radius: 12px;
    font-size: 0.85rem;
    font-weight: 600;
}

.badge-high {
    background: #FEE2E2;
    color: #991B1B;
}

.badge-medium {
    background: #FEF3C7;
    color: #92400E;
}

.badge-low {
    background: #D1FAE5;
    color: #065F46;
}

/* Filters */
.filters-bar {
    margin-bottom: 20px;
    display: flex;
    gap: 15px;
    flex-wrap: wrap;
    padding: 15px;
    background: #F3F4F6;
    border-radius: 8px;
}

.filter-group {
    display: flex;
    align-items: center;
    gap: 8px;
}

.filter-group label {
    font-weight: 600;
    font-size: 0.9rem;
    color: #374151;
}

.filter-group select {
    padding: 8px 12px;
    border: 1px solid #D1D5DB;
    border-radius: 6px;
    font-size: 0.95rem;
    background: white;
    cursor: pointer;
}

/* Hierarchical Tree */
.hierarchy-tree {
    border: 1px solid #E5E7EB;
    border-radius: 8px;
    overflow: hidden;
}

.domain-header {
    background: linear-gradient(135deg, #667EEA 0%, #764BA2 100%);
    color: white;
    padding: 15px 20px;
    cursor: pointer;
    display: flex;
    align-items: center;
    gap: 12px;
    font-weight: 600;
    font-size: 1.1rem;
    transition: opacity 0.2s;
}

.domain-header:hover {
    opacity: 0.9;
}

.domain-header .toggle-icon {
    font-size: 1rem;
    transition: transform 0.3s;
}

.domain-header.collapsed .toggle-icon {
    transform: rotate(-90deg);
}

.domain-content {
    border-top: 1px solid #E5E7EB;
}

.subdomain-header {
    background: #F3F4F6;
    padding: 12px 20px 12px 40px;
    cursor: pointer;
    display: flex;
    align-items: center;
    gap: 10px;
    font-weight: 600;
    color: #374151;
    border-bottom: 1px solid #E5E7EB;
    transition: background 0.2s;
}

.subdomain-header:hover {
    background: #E5E7EB;
}

.subdomain-header .toggle-icon {
    font-size: 0.9rem;
    transition: transform 0.3s;
}

.subdomain-header.collapsed .toggle-icon {
    transform: rotate(-90deg);
}

.risk-item {
    padding: 15px 20px 15px 60px;
    border-bottom: 1px solid #F3F4F6;
    transition: background 0.2s;
    cursor: pointer;
}

.risk-item:hover {
    background: #F9FAFB;
}

.risk-item:last-child {
    border-bottom: none;
}

.risk-header {
    display: grid;
    grid-template-columns: 2fr 1fr 1fr 1fr 1fr;
    gap: 15px;
    align-items: center;
}

.risk-title {
    font-weight: 600;
    color: #111827;
    font-size: 0.95rem;
}

.risk-details {
    margin-top: 15px;
    padding: 15px;
    background: #F9FAFB;
    border-left: 4px solid #667EEA;
    border-radius: 4px;
    display: none;
}

.risk-details.expanded {
    display: block;
}

.detail-section {
    margin-bottom: 15px;
}

.detail-section:last-child {
    margin-bottom: 0;
}

.detail-label {
    font-weight: 600;
    color: #111827;
    font-size: 0.9rem;
    margin-bottom: 5px;
    display: block;
}

.detail-text {
    color: #374151;
    line-height: 1.6;
    font-size: 0.9rem;
}

/* Follow-up specific styles: display as separated blocks (no bullets) */
.followups {
    display: block;
}
.followup-item {
    padding: 8px 12px;
    margin-bottom: 8px;
    background: #FFFFFF;
    border: 1px solid #E6E9EE;
    border-radius: 6px;
    /* Align font with main detail-text */
    font-size: 0.9rem;
    line-height: 1.6;
    color: #374151;
    font-family: inherit;
}
.followup-q {
    font-weight: 600;
    color: #111827;
    margin-bottom: 4px;
    font-size: 0.9rem;
    line-height: 1.6;
}
.followup-a {
    color: #374151;
    font-size: 0.9rem;
    line-height: 1.6;
}

/* Answer chips for multiple-choice / checkbox responses */
.answer-chips {
    display: flex;
    gap: 8px;
    flex-wrap: wrap;
    margin-top: 6px;
}
.answer-chip {
    display: inline-flex;
    align-items: center;
    background: white;
    border: 1px solid #E6E9EE;
    padding: 6px 10px;
    border-radius: 999px;
    font-size: 0.9rem;
    line-height: 1.4;
    color: #374151;
    box-shadow: 0 1px 2px rgba(15,23,42,0.04);
}

.causality-grid {
    display: grid;
    grid-template-columns: repeat(3, 1fr);
    gap: 10px;
    margin-top: 10px;
}

.causality-box {
    background: white;
    padding: 10px;
    border-radius: 6px;
    border-left: 3px solid;
}

.causality-box.entity {
    border-left-color: #3B82F6;
}

.causality-box.timing {
    border-left-color: #10B981;
}

.causality-box.intent {
    border-left-color: #F59E0B;
}

.causality-box-label {
    font-size: 0.75rem;
    font-weight: 600;
    color: #6B7280;
    text-transform: uppercase;
    margin-bottom: 4px;
}

.causality-box-text {
    font-size: 0.85rem;
    color: #374151;
    line-height: 1.4;
}

@media (max-width: 768px) {
    .risk-header {
        grid-template-columns: 1fr;
    }
    .causality-grid {
        grid-template-columns: 1fr;
    }
}

/* Pattern Info Section */
.pattern-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    margin-bottom: 15px;
    padding: 10px 0;
}

.info-toggle {
    background: linear-gradient(135deg, #667EEA 0%, #764BA2 100%);
    color: white;
    border: none;
    padding: 10px 20px;
    border-radius: 8px;
    font-size: 0.9rem;
    font-weight: 600;
    cursor: pointer;
    transition: all 0.3s ease;
    box-shadow: 0 2px 8px rgba(102, 126, 234, 0.3);
}

.info-toggle:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.5);
}

.pattern-info-box {
    background: linear-gradient(135deg, #F3F4F6 0%, #E5E7EB 100%);
    border: 2px solid #667EEA;
    border-radius: 12px;
    padding: 25px;
    margin-bottom: 20px;
    max-height: 800px;
    overflow-y: auto;
    transition: all 0.4s ease;
    opacity: 1;
}

.pattern-info-box.collapsed {
    max-height: 0;
    padding: 0 25px;
    margin-bottom: 0;
    opacity: 0;
    overflow: hidden;
    border-width: 0;
}

.pattern-info-box h4 {
    color: #374151;
    font-size: 1.3rem;
    margin-top: 0;
    margin-bottom: 15px;
    border-bottom: 2px solid #667EEA;
    padding-bottom: 10px;
}

.pattern-info-box h5 {
    color: #4B5563;
    font-size: 1.1rem;
    margin-top: 15px;
    margin-bottom: 10px;
}

.pattern-info-box p {
    color: #374151;
    line-height: 1.6;
    margin-bottom: 15px;
}

.pattern-info-box ul {
    margin: 10px 0;
    padding-left: 20px;
}

.pattern-info-box li {
    color: #4B5563;
    line-height: 1.8;
    margin-bottom: 8px;
}

.pattern-category {
    background: white;
    border-left: 4px solid #667EEA;
    padding: 15px;
    margin: 15px 0;
    border-radius: 8px;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.05);
}

/* Domain Info Section */
.domain-info-box {
    background: linear-gradient(135deg, #EFF6FF 0%, #DBEAFE 100%);
    border: 2px solid #3B82F6;
    border-radius: 12px;
    padding: 25px;
    margin-bottom: 20px;
    max-height: 800px;
    overflow-y: auto;
    transition: all 0.4s ease;
    opacity: 1;
}

.domain-info-box.collapsed {
    max-height: 0;
    padding: 0 25px;
    margin-bottom: 0;
    opacity: 0;
    overflow: hidden;
    border-width: 0;
}

.domain-info-box h4 {
    color: #1E40AF;
    font-size: 1.3rem;
    margin-top: 0;
    margin-bottom: 15px;
    border-bottom: 2px solid #3B82F6;
    padding-bottom: 10px;
}

.domain-info-box h5 {
    color: #1E40AF;
    font-size: 1.1rem;
    margin-top: 15px;
    margin-bottom: 10px;
}

.domain-info-box p {
    color: #374151;
    line-height: 1.7;
    margin-bottom: 15px;
    text-align: justify;
}

.domain-category {
    background: white;
    border-left: 4px solid #3B82F6;
    padding: 15px;
    margin: 15px 0;
    border-radius: 8px;
    box-shadow: 0 2px 8px rgba(59, 130, 246, 0.1);
}

.domain-category h5 {
    margin-top: 0;
    color: #1E40AF;
    font-weight: 700;
}

.domain-category p {
    margin-bottom: 15px;
    color: #4B5563;
    line-height: 1.7;
}

/* Subdomain Cards */
.subdomain-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(280px, 1fr));
    gap: 10px;
    margin-top: 15px;
}

.subdomain-card {
    background: linear-gradient(135deg, #EFF6FF 0%, #DBEAFE 100%);
    border: 1px solid #93C5FD;
    border-radius: 8px;
    padding: 10px 12px;
    display: flex;
    align-items: center;
    gap: 10px;
    transition: all 0.2s ease;
}

.subdomain-card:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 8px rgba(59, 130, 246, 0.2);
    border-color: #3B82F6;
}

.subdomain-id {
    background: #3B82F6;
    color: white;
    font-weight: 700;
    font-size: 0.75rem;
    padding: 4px 8px;
    border-radius: 4px;
    flex-shrink: 0;
    min-width: 32px;
    text-align: center;
}

.subdomain-name {
    color: #1E40AF;
    font-size: 0.85rem;
    line-height: 1.4;
    font-weight: 500;
}

/* Alert Info Section */
.alert-info-box {
    background: linear-gradient(135deg, #FEF2F2 0%, #FEE2E2 100%);
    border: 2px solid #DC2626;
    border-radius: 12px;
    padding: 25px;
    margin-bottom: 20px;
    max-height: 600px;
    overflow-y: auto;
    transition: all 0.4s ease;
    opacity: 1;
}

.alert-info-box.collapsed {
    max-height: 0;
    padding: 0 25px;
    margin-bottom: 0;
    opacity: 0;
    overflow: hidden;
    border-width: 0;
}

.alert-info-box h4 {
    color: #991B1B;
    font-size: 1.3rem;
    margin-top: 0;
    margin-bottom: 15px;
    border-bottom: 2px solid #DC2626;
    padding-bottom: 10px;
}

.alert-info-box h5 {
    color: #B91C1C;
    font-size: 1.1rem;
    margin-top: 15px;
    margin-bottom: 10px;
}

.alert-info-box p {
    color: #374151;
    line-height: 1.7;
    margin-bottom: 15px;
    text-align: justify;
}

.alert-dimension {
    background: white;
    border-left: 4px solid #DC2626;
    padding: 12px 15px;
    margin: 10px 0;
    border-radius: 8px;
    box-shadow: 0 2px 8px rgba(220, 38, 38, 0.1);
    color: #4B5563;
    line-height: 1.6;
}

/* Sankey Info Section */
.sankey-info-box {
    background: linear-gradient(135deg, #FFFBEB 0%, #FEF3C7 100%);
    border: 2px solid #F59E0B;
    border-radius: 12px;
    padding: 25px;
    margin-bottom: 20px;
    max-height: 600px;
    overflow-y: auto;
    transition: all 0.4s ease;
    opacity: 1;
}

.sankey-info-box.collapsed {
    max-height: 0;
    padding: 0 25px;
    margin-bottom: 0;
    opacity: 0;
    overflow: hidden;
    border-width: 0;
}

.sankey-info-box h4 {
    color: #92400E;
    font-size: 1.3rem;
    margin-top: 0;
    margin-bottom: 15px;
    border-bottom: 2px solid #F59E0B;
    padding-bottom: 10px;
}

.sankey-info-box h5 {
    color: #B45309;
    font-size: 1.1rem;
    margin-top: 15px;
    margin-bottom: 10px;
}

.sankey-info-box p {
    color: #374151;
    line-height: 1.7;
    margin-bottom: 15px;
    text-align: justify;
}

.sankey-info-box ul {
    margin: 10px 0;
    padding-left: 0;
    list-style: none;
}

.sankey-info-box li {
    color: #4B5563;
    line-height: 1.8;
    margin-bottom: 8px;
    padding-left: 10px;
}

.sankey-dimension {
    background: white;
    border-left: 4px solid #F59E0B;
    padding: 12px 15px;
    margin: 10px 0;
    border-radius: 8px;
    box-shadow: 0 2px 8px rgba(245, 158, 11, 0.1);
    color: #4B5563;
    line-height: 1.6;
}

/* Charts - Chart containers and grid */

.chart-container {
    background: white;
    padding: 20px;
    border-radius: 12px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    min-height: 400px;
}

.chart-container-large {
    background: white;
    padding: 20px;
    border-radius: 12px;
    box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    min-height: 500px;
}

    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üõ°Ô∏è AI Risk Analysis Report</h1>
            <h2>Comprehensive Risk Assessment & Mitigation Strategy</h2>
            <div class="report-meta-actions">
                <div class="report-links">
                    <button id="download-zip-btn" class="meta-link secondary" onclick="handleDownloadClick()">Download Report</button>
                    <button id="view-analysis-btn" class="meta-link secondary" onclick="openAnalysisJson()">View Analysis JSON</button>
                    
                    
                    <a class="meta-link secondary" href="https://docs.google.com/presentation/d/1wxg-hZAjGvFHcsfnEp1KAJJo5xvf98MB2v50B5URXZM/edit?slide=id.g32ebda0938f_6_0#slide=id.g32ebda0938f_6_0" target="_blank" rel="noopener">MIT Causal Taxonomy: v0.1</a>
                    <a class="meta-link secondary" href="https://docs.google.com/presentation/d/1wxg-hZAjGvFHcsfnEp1KAJJo5xvf98MB2v50B5URXZM/edit?slide=id.g325f13b19c4_0_0#slide=id.g325f13b19c4_0_0" target="_blank" rel="noopener">MIT Domain Taxonomy: v0.1</a>
                </div>

            </div>
        </header>
            <!-- Embed metadata JSON for client-side zip creation -->
            <script id="report-metadata" type="application/json">{"executive_summary_text": "This analysis provides a comprehensive overview of the risks associated with our AI system, focusing on its operational and societal implications, revealing a global risk score of 65.0, which indicates a high overall risk level. The most critical area identified is \u0027Malicious actors,\u0027 presenting 3 high-severity risks, especially regarding disinformation, surveillance, and influence at scale. Following closely are \u0027AI system safety, failures, \u0026 limitations\u0027 with 2 high-severity risks, and \u0027Socioeconomic \u0026 Environmental\u0027 with 1 high-severity risk. In total, 22 risks were analyzed, categorized as 3 low, 10 medium, and 9 high-severity. A critical risk concentration is observed, making up 40.91% of all risks, alongside a significant accumulation of medium risks at 45.45%. Notably, intentional threats constitute 9 risks, representing 55.56% of high intentional risks, with 6 malicious human risks and 3 high-threat attacks highlighted. This underscores a primary concern of high risk concentration, warranting a focused prevention approach. Therefore, the recommended action is to prioritize robust prevention strategies across all identified risk areas.", "language": "en", "profile": "expert", "run_id": "97986f3e4a874e5f90eac3951ad89f80", "timestamp": "2025-12-16 19:09:34"}</script>
            <!-- Embed analysis and heuristic JSON so the report can open them in a new tab -->
            <script id="report-analysis" type="application/json">{"1.1": {"risks": [{"causality": {"entity": {"rationale": "The risk is caused by the AI\u0027s inference mechanism and content generation, which are functions of the AI system itself.", "value": "ai"}, "intent": {"rationale": "The system\u0027s goal is to tailor output for relevance, but biases lead to an unintended outcome of unfair differentiation.", "value": "unintentional"}, "timing": {"rationale": "The root cause of bias in inference and content generation is typically introduced during the AI model\u0027s development and training phases.", "value": "pre-deployment"}}, "explanation": "The system collects anonymized interaction logs and infers user roles (e.g., \u0027developer\u0027, \u0027researcher\u0027) to tailor output relevance and complexity. If the inference mechanism for these roles is biased, or if the content generation and tailoring are not equally robust across all inferred groups, it could lead to unequal quality of service or content, potentially perpetuating existing professional biases or creating new forms of discrimination.", "mitigation": "Conduct regular bias audits on role inference mechanisms and content generation models to ensure equitable performance and relevance across all user roles. Implement diverse datasets for training and validation, and allow users to manually correct or confirm their roles to minimize inference errors. Establish feedback channels for users to report perceived unfairness.", "severity": "medium", "severity_rationale": "The risk can lead to unequal quality of service and perpetuate professional biases, affecting a subset of users, hence medium severity.", "title": "Unfair differentiation based on inferred roles"}]}, "1.2": {"risks": [{"causality": {"entity": {"rationale": "The AI system directly generates the content, which becomes harmful or biased due to its inherent programming or training.", "value": "ai"}, "intent": {"rationale": "The system is designed to generate helpful content, but due to biases or lack of constraints, it unintentionally produces harmful outputs.", "value": "unintentional"}, "timing": {"rationale": "The risk manifests when the AI is deployed and actively generates content in response to user inputs.", "value": "post-deployment"}}, "explanation": "The system generates various forms of content including text, code, structured data, and recommendations. There is an inherent risk that, if not properly constrained or if trained on biased datasets, the system could generate content that is toxic, offensive, discriminatory, or perpetuates harmful stereotypes. This risk extends beyond text to potentially biased code or misleading recommendations.", "mitigation": "Implement robust content filtering mechanisms and safety classifiers for all generated outputs. Conduct regular adversarial testing and red-teaming exercises to identify and mitigate biases and harmful content generation. Incorporate Reinforcement Learning from Human Feedback (RLHF) specifically for safety and ethical content generation, continuously refining models based on user reports of harmful outputs.", "severity": "medium", "severity_rationale": "The generation of harmful or biased content can lead to user distress, reputational damage, and perpetuation of stereotypes, meriting a medium severity.", "title": "Generation of harmful or biased content"}]}, "1.3": {"risks": [{"causality": {"entity": {"rationale": "The disparate performance and accuracy are direct outputs and characteristics of the AI system\u0027s behavior.", "value": "ai"}, "intent": {"rationale": "The system\u0027s goal is to perform well for all users, but it unintentionally performs disparately across groups.", "value": "unintentional"}, "timing": {"rationale": "The root causes of disparate performance typically stem from biases introduced during the model\u0027s development and training (e.g., imbalanced datasets, lack of representation).", "value": "pre-deployment"}}, "explanation": "The system explicitly acknowledges the possibility of differences in performance or accuracy across various user groups. This means that certain demographics, professional roles, or groups based on interaction patterns may receive lower quality, less accurate, or less relevant outputs compared to others, leading to an unequal user experience.", "mitigation": "Implement continuous monitoring of performance metrics segmented by identified user groups or inferred roles. Conduct thorough fairness evaluations and debiasing techniques during model development and deployment. Actively seek feedback from diverse user groups to identify and address performance disparities, potentially by fine-tuning models on representative datasets for underperforming groups.", "severity": "high", "severity_rationale": "Disparate performance can lead to significant inequities and an unequal user experience for certain groups, potentially hindering their work or progress.", "title": "Disparate performance and accuracy across user groups"}]}, "2.1": {"risks": [{"causality": {"entity": {"rationale": "Re-identification is caused by malicious actors employing sophisticated techniques, a human action.", "value": "human"}, "intent": {"rationale": "The act of re-identifying anonymized data by malicious actors is a deliberate action to compromise privacy.", "value": "intentional"}, "timing": {"rationale": "Re-identification attempts would occur against collected, anonymized data from a deployed system.", "value": "post-deployment"}}, "explanation": "Although the system explicitly states that no personally identifiable information (PII) is directly collected or stored, it does collect \u0027anonymized user interaction logs\u0027. There is a residual, albeit low, risk that sophisticated re-identification techniques, especially when combined with external datasets, could potentially link this anonymized data back to individuals, inadvertently compromising privacy.", "mitigation": "Implement robust anonymization techniques that go beyond simple masking, such as k-anonymity or differential privacy, for interaction logs. Regularly review and update anonymization protocols based on the latest research and best practices. Restrict access to anonymized data and ensure that any combination with external datasets is strictly controlled and audited for re-identification risks.", "severity": "low", "severity_rationale": "While the risk exists, it\u0027s described as \u0027residual\u0027 and \u0027low,\u0027 indicating a lower likelihood of widespread harm, though privacy is a fundamental concern.", "title": "Potential for re-identification of anonymized data"}]}, "2.2": {"risks": [{"causality": {"entity": {"rationale": "The attacks are carried out by human adversaries, although the system\u0027s vulnerability is a contributing factor.", "value": "human"}, "intent": {"rationale": "Cyberattacks are deliberate and malicious actions undertaken by human actors.", "value": "intentional"}, "timing": {"rationale": "Cyberattacks typically target a deployed system in operation.", "value": "post-deployment"}}, "explanation": "The system\u0027s security measures are described as \u0027basic controls\u0027 (e.g., authentication, encryption). While essential, these may not be sufficient to protect against advanced and sophisticated cyberattacks such as adversarial attacks against the AI model itself, data poisoning, model inversion, or side-channel attacks that could compromise the integrity of the generated outputs, intellectual property, or overall system operation.", "mitigation": "Implement a multi-layered security strategy beyond basic controls, including advanced threat detection, intrusion prevention systems, and regular penetration testing. Specifically for AI, deploy techniques to detect and mitigate adversarial attacks (e.g., input validation, robust model training) and data poisoning. Conduct regular security audits and maintain an incident response plan tailored for AI systems.", "severity": "medium", "severity_rationale": "Advanced cyberattacks can compromise system integrity, data, and intellectual property, leading to significant operational disruptions and losses.", "title": "Vulnerability to advanced cyberattacks"}]}, "3.1": {"risks": [{"causality": {"entity": {"rationale": "The AI system itself generates the inaccurate or misleading information.", "value": "ai"}, "intent": {"rationale": "The system\u0027s purpose is to provide accurate information; the generation of inaccuracies is an unintended failure.", "value": "unintentional"}, "timing": {"rationale": "The inaccuracies are produced when the AI is queried by users after its deployment.", "value": "post-deployment"}}, "explanation": "The system produces or suggests information aimed at the public or large groups, generating text, code, structured data, and recommendations. There is a high risk that the system could produce factual inaccuracies, \u0027hallucinate\u0027 information, provide incorrect code, or offer misleading recommendations, especially when summarizing complex papers, generating hypotheses, or assisting with debugging in technical research and software development.", "mitigation": "Implement robust fact-checking mechanisms and external validation sources for generated content. Clearly indicate the probabilistic nature of AI-generated content and emphasize the need for human verification. Utilize human-in-the-loop validation for critical outputs. Continuously update and refine training data to reduce factual errors and hallucinations, and specifically train the model to recognize and communicate its uncertainties.", "severity": "high", "severity_rationale": "Inaccurate or misleading information, especially in technical or research contexts, can lead to significant errors, flawed decisions, and negative outcomes.", "title": "Generation of inaccurate or misleading information"}]}, "3.2": {"risks": [{"causality": {"entity": {"rationale": "The personalization algorithms, which are functions of the AI system, inadvertently create filter bubbles.", "value": "ai"}, "intent": {"rationale": "Personalization is intended to improve relevance, but the creation of filter bubbles is an unintended negative consequence.", "value": "unintentional"}, "timing": {"rationale": "Filter bubbles develop over time through user interaction with the deployed system.", "value": "post-deployment"}}, "explanation": "The system personalizes its output or filters content based on user profiles or interactions. While intended to improve relevance, this personalization can inadvertently create \u0027filter bubbles,\u0027 limiting users\u0027 exposure to diverse information, alternative perspectives, or challenging viewpoints. This can reinforce existing biases, contribute to an insular understanding of complex topics, and fragment the information ecosystem.", "mitigation": "Introduce features that encourage exposure to diverse viewpoints, such as \u0027show alternative perspectives\u0027 or \u0027what others are reading/doing.\u0027 Periodically audit personalization algorithms to ensure they don\u0027t exclusively reinforce existing beliefs. Provide users with control over their personalization settings, allowing them to adjust the degree of filtering or explore broader content.", "severity": "medium", "severity_rationale": "Filter bubbles can limit diverse information exposure and reinforce biases, potentially leading to social and cognitive harm, thus medium severity.", "title": "Filter bubbles and reinforcement of existing biases"}]}, "4.1": {"risks": [{"causality": {"entity": {"rationale": "Malicious human actors are the agents who exploit the AI system for disinformation and influence operations.", "value": "human"}, "intent": {"rationale": "The exploitation of the system by malicious actors is a deliberate act with an intent to manipulate or spread disinformation.", "value": "intentional"}, "timing": {"rationale": "The exploitation occurs after the system has been deployed and is accessible for use by actors.", "value": "post-deployment"}}, "explanation": "The system\u0027s capacity to generate information aimed at the public or large groups, coupled with its personalization capabilities, makes it highly susceptible to exploitation by malicious actors. It could be used to create and disseminate convincing disinformation, manipulate public opinion, or orchestrate large-scale influence operations. Even anonymized interaction logs could be leveraged for profiling user behavior to enhance targeted content delivery for malicious purposes.", "mitigation": "Implement stringent usage policies and terms of service that explicitly prohibit the use of the system for disinformation or manipulation. Develop advanced anomaly detection systems to identify patterns indicative of malicious large-scale content generation or coordinated influence attempts. Partner with disinformation researchers and fact-checking organizations to stay ahead of evolving threats. Restrict access to sensitive capabilities for unverified users.", "severity": "high", "severity_rationale": "Exploitation for large-scale disinformation can severely impact public opinion, democratic processes, and societal stability, posing a high risk.", "title": "Exploitation for large-scale disinformation and influence"}]}, "4.2": {"risks": [{"causality": {"entity": {"rationale": "Malicious human actors are the primary agents who would abuse the AI\u0027s capabilities for harmful code generation and cyberattack enablement.", "value": "human"}, "intent": {"rationale": "The abuse of the system for malicious code generation or cyberattacks is a deliberate and harmful act by malicious actors.", "value": "intentional"}, "timing": {"rationale": "This abuse occurs when the system is deployed and its capabilities are accessible to malicious actors.", "value": "post-deployment"}}, "explanation": "The system\u0027s ability to generate code, assist in debugging, and suggest architectural designs, combined with the explicit acknowledgment that it could be vulnerable or adaptable for cyberattacks or malware, presents a critical risk. Malicious actors could exploit these capabilities to generate vulnerabilities in software, develop sophisticated malware, aid in constructing cyberattack tools, or even be misused in contexts related to autonomous weapon development, leading to significant large-scale harm.", "mitigation": "Implement strict content filtering and code analysis tools specifically designed to detect and block the generation of malicious code patterns or instructions for harmful use cases. Incorporate ethical hacking principles into safety testing, actively probing the system for its ability to generate harmful outputs. Restrict or gate access to advanced code generation capabilities and mandate human oversight for outputs in sensitive domains. Establish a robust reporting mechanism for potential misuse and collaborate with cybersecurity experts.", "severity": "high", "severity_rationale": "The generation of malicious code or assistance in cyberattacks can lead to severe system compromises, data breaches, and large-scale harm.", "title": "Abuse for malicious code generation and cyberattack enablement"}]}, "4.3": {"risks": [{"causality": {"entity": {"rationale": "Malicious human actors leverage the AI\u0027s capabilities to perform fraud and targeted manipulation.", "value": "human"}, "intent": {"rationale": "Fraud and targeted manipulation are deliberate acts by malicious actors.", "value": "intentional"}, "timing": {"rationale": "This risk manifests when malicious actors interact with the deployed AI system to execute fraudulent activities.", "value": "post-deployment"}}, "explanation": "The system\u0027s capacity to generate personalized content and recommendations, coupled with the direct admission that it could be used for fraud or targeted manipulation, signifies a considerable risk. Malicious actors could leverage these capabilities to create highly convincing phishing attempts, elaborate scams, or sophisticated psychological manipulation tactics aimed at individuals or specific user groups, potentially leading to financial loss, identity theft, or other forms of harm.", "mitigation": "Develop advanced anomaly detection and content filtering to identify patterns indicative of fraudulent or manipulative intent. Implement user education programs to raise awareness about AI-powered scams. Provide clear disclaimers on AI-generated content regarding its potential for misuse. Regularly update threat intelligence and integrate it into the system\u0027s safety protocols to counter evolving fraud techniques.", "severity": "high", "severity_rationale": "The facilitation of fraud and targeted manipulation can lead to significant financial loss, identity theft, and psychological harm to individuals, warranting high severity.", "title": "Facilitation of fraud and targeted manipulation"}]}, "5.1": {"risks": [{"causality": {"entity": {"rationale": "The primary cause is human over-reliance and lack of verification of AI outputs.", "value": "human"}, "intent": {"rationale": "Users over-rely on the system for efficiency, not with the intention to introduce errors; the errors are unintended consequences.", "value": "unintentional"}, "timing": {"rationale": "Over-reliance occurs when human users interact with the deployed AI system during their work.", "value": "post-deployment"}}, "explanation": "The system is used in high-stakes environments, including \u0027assisting in the development of safety-critical systems.\u0027 Given that the system can generate inaccurate information (3.1) and exhibit unequal performance across groups (1.3), there\u0027s a significant risk that human users might over-rely on its outputs (code, debugging assistance, architectural designs) without adequate verification. This could lead to critical errors, system failures, or severe consequences in safety-critical applications.", "mitigation": "Implement mandatory human oversight and rigorous validation processes for all AI-generated outputs, especially in safety-critical domains. Clearly communicate the system\u0027s limitations and potential for error to users. Integrate the system with existing robust verification and validation tools. Introduce warnings and checks to prevent or flag unverified deployment of AI-generated content in critical systems. Promote a culture of critical evaluation rather than blind trust in AI outputs.", "severity": "high", "severity_rationale": "Overreliance in safety-critical systems can lead to catastrophic failures, severe injuries, or loss of life, representing a high severity risk.", "title": "Overreliance leading to errors in safety-critical systems"}]}, "5.2": {"risks": [{"causality": {"entity": {"rationale": "The risk primarily stems from human cognitive biases and over-reliance, even though the AI provides the suggestions.", "value": "human"}, "intent": {"rationale": "The AI is designed to assist, not to diminish human agency or critical evaluation; these are unintended side effects on human users.", "value": "unintentional"}, "timing": {"rationale": "This subtle influence and cognitive anchoring develop over time through ongoing human interaction with the deployed system.", "value": "post-deployment"}}, "explanation": "While the system explicitly states it \u0027only suggests\u0027 and makes \u0027no binding decisions,\u0027 its role in providing code, research summaries, and architectural designs can subtly yet significantly influence user choices. Over time, users might become over-reliant on these suggestions, leading to cognitive anchoring, reduced critical evaluation, and a diminished sense of agency in their professional decision-making, even without direct automation of decisions.", "mitigation": "Design the system to present suggestions as one of several options, encouraging users to explore alternatives and justify their choices. Incorporate features that prompt users for critical review and feedback on suggestions. Implement educational modules that train users on effective human-AI collaboration, emphasizing independent verification and critical assessment of AI outputs. Monitor for patterns of over-acceptance of AI suggestions.", "severity": "medium", "severity_rationale": "Subtle influence leading to reduced critical evaluation can impact professional decision-making and innovation, meriting a medium severity.", "title": "Subtle influence and cognitive anchoring"}]}, "6.1": {"risks": [{"causality": {"entity": {"rationale": "This risk arises from a complex interaction of the AI\u0027s technical requirements and existing societal/economic structures, making it attributable to \u0027other\u0027 systemic factors.", "value": "other"}, "intent": {"rationale": "The system aims to provide benefits, but unintentionally exacerbates existing societal inequalities.", "value": "unintentional"}, "timing": {"rationale": "The exacerbation of the digital divide becomes apparent as the system is adopted and used within society.", "value": "post-deployment"}}, "explanation": "The system\u0027s benefits are primarily accessible to software developers, researchers, and technical professionals, with a stated \u0027potential for exclusion of individuals or organizations lacking the technical infrastructure or expertise to effectively leverage the system.\u0027 This creates a risk of exacerbating the digital divide, leading to an unfair distribution of productivity gains and potentially centralizing power among technologically advanced entities and the AI providers, leaving others behind.", "mitigation": "Develop tiered access models, including free or subsidized versions for educational institutions or developing regions. Provide comprehensive training and support to lower the barrier to entry for users lacking expertise. Actively seek partnerships to democratize access to the technology. Promote open standards or interoperability to reduce vendor lock-in and enable diverse ecosystem participation.", "severity": "medium", "severity_rationale": "Exacerbating the digital divide and centralizing power can lead to significant societal inequities and unequal opportunities, thus medium severity.", "title": "Exacerbation of digital divide and power centralization"}]}, "6.2": {"risks": [{"causality": {"entity": {"rationale": "The AI\u0027s inherent capability to automate tasks is the direct cause of job displacement.", "value": "ai"}, "intent": {"rationale": "The automation of tasks is an intentional design goal of the AI, even if job displacement is a secondary, undesirable outcome.", "value": "intentional"}, "timing": {"rationale": "Job displacement occurs as the AI system is widely adopted and integrated into human workflows and industries.", "value": "post-deployment"}}, "explanation": "The system\u0027s ability to automate tasks such as code generation, debugging assistance, documentation creation, and knowledge retrieval directly leads to the acknowledged risk of employment reduction. This could result in job displacement for certain technical roles, requiring a significant reskilling of the workforce, and potentially exacerbating economic inequalities if not proactively managed.", "mitigation": "Invest in reskilling and upskilling programs for workers in roles impacted by AI automation, focusing on skills that complement AI capabilities (e.g., AI oversight, ethical AI development, complex problem-solving). Collaborate with educational institutions to adapt curricula for future job markets. Explore models for job creation in AI development, maintenance, and oversight. Implement policies that support workers transitioning between roles.", "severity": "high", "severity_rationale": "Job displacement can have severe economic and social consequences for individuals and society, hence high severity.", "title": "Job displacement and skill obsolescence"}]}, "6.3": {"risks": [{"causality": {"entity": {"rationale": "The risk stems from human over-reliance and a societal/cultural shift in valuing human expertise.", "value": "human"}, "intent": {"rationale": "The AI is designed to assist and augment, not to devalue human expertise; this is an unintended societal consequence.", "value": "unintentional"}, "timing": {"rationale": "This devaluation occurs over time as humans interact with the deployed system and cultural perceptions shift.", "value": "post-deployment"}}, "explanation": "The system explicitly replaces human activities in areas like code generation, research summarization, and technical explanations. This carries the risk of diminishing the perceived value of human professional expertise and creativity in these domains. Over-reliance on homogenized AI outputs could stifle innovation, reduce the incentive for humans to develop nuanced skills, and lead to a cultural devaluation of unique human intellectual contributions.", "mitigation": "Position the AI system as an assistive tool rather than a replacement, emphasizing human-AI collaboration. Highlight the unique value of human creativity, critical thinking, and contextual understanding. Promote the use of AI to augment human capabilities, freeing up time for more complex, creative, or strategic tasks. Foster communities where human experts share novel AI applications and critical insights.", "severity": "medium", "severity_rationale": "Devaluation of human expertise and creativity can stifle innovation and lead to a loss of valuable human capital, meriting medium severity.", "title": "Devaluation of human professional expertise and creativity"}]}, "6.4": {"risks": []}, "6.5": {"risks": [{"causality": {"entity": {"rationale": "Governance is a human responsibility; its inadequacy is a failure in human design or implementation of oversight.", "value": "human"}, "intent": {"rationale": "While governance is formalized with good intent, its inadequacy is an unintended shortcoming or oversight.", "value": "unintentional"}, "timing": {"rationale": "The inadequacy of governance refers to flaws in the framework that are typically designed or established before deployment, though they may manifest later.", "value": "pre-deployment"}}, "explanation": "While \u0027formalized governance\u0027 is stated to exist, the scope and effectiveness of this governance in comprehensively addressing all identified risks (e.g., high severity risks from malicious use, ethical implications of advanced capabilities, employment impacts, and potential for overreliance in safety-critical systems) are not detailed. There\u0027s a residual risk that the existing governance, despite being formalized, may not be sufficiently robust, agile, or comprehensive to anticipate and mitigate the full spectrum of evolving AI-specific risks.", "mitigation": "Establish a multidisciplinary AI ethics and governance board with external experts. Implement a continuous risk assessment framework that adapts to new capabilities and uses. Develop clear accountability structures for AI system development and deployment. Regularly review and update governance policies to ensure they cover emerging AI risks and align with best practices and regulatory requirements.", "severity": "medium", "severity_rationale": "Inadequate governance can lead to unmanaged risks with broad societal and ethical implications, potentially resulting in high-severity issues if not addressed.", "title": "Potential for governance inadequacy"}]}, "6.6": {"risks": [{"causality": {"entity": {"rationale": "The AI system\u0027s computational requirements (training and inference) are the direct cause of high energy consumption.", "value": "ai"}, "intent": {"rationale": "The use of large-scale GPU clusters for computational power is an intentional design choice for AI performance, with environmental impact being an expected, though undesired, consequence.", "value": "intentional"}, "timing": {"rationale": "Energy consumption for AI occurs during both the pre-deployment (training) and post-deployment (inference) phases, making it span both timings.", "value": "other"}}, "explanation": "The system relies on \u0027large-scale GPU clusters for training and inference\u0027 and involves \u0027significant computational power and energy consumption,\u0027 primarily hosted on cloud platforms. This inherently creates a substantial environmental footprint through increased carbon emissions and resource depletion associated with powering data centers, contributing to climate change, despite ongoing assessments and efforts towards greener solutions.", "mitigation": "Prioritize research and development into more energy-efficient AI models and algorithms (e.g., model compression, quantization). Optimize inference processes to minimize computational overhead. Partner with cloud providers committed to renewable energy sources and sustainable data center operations. Publicly report on the system\u0027s energy consumption and carbon footprint, setting targets for reduction.", "severity": "medium", "severity_rationale": "Significant energy consumption contributes to environmental degradation and climate change, representing a medium severity societal impact.", "title": "Significant environmental impact due to energy consumption"}]}, "7.1": {"risks": [{"causality": {"entity": {"rationale": "The subtle divergence from human values or production of emergent behaviors are characteristics of the AI system\u0027s operation.", "value": "ai"}, "intent": {"rationale": "The system is designed for alignment with human objectives; divergence or emergent behaviors are unintended failures of this alignment.", "value": "unintentional"}, "timing": {"rationale": "Subtle misalignments and emergent behaviors typically manifest during the AI system\u0027s operation in real-world, unforeseen edge cases.", "value": "post-deployment"}}, "explanation": "Despite employing robust alignment mechanisms like RLHF, safety filtering, and adversarial testing, defining \u0027accurate, relevant, and helpful\u0027 for a complex AI in all contexts is challenging. There\u0027s a residual risk that the system\u0027s behavior, while ostensibly aligned with its defined success criteria, might subtly diverge from deeper human values or produce undesirable emergent behaviors in unforeseen edge cases, especially if proxy metrics for success don\u0027t fully capture the breadth of human goals and potential negative externalities.", "mitigation": "Continuously refine the alignment process by incorporating diverse human feedback and perspectives. Implement \u0027red-teaming\u0027 exercises with a focus on uncovering subtle misalignments and unexpected behaviors. Develop more comprehensive and robust evaluation metrics that go beyond direct performance to include ethical and societal impacts. Foster interdisciplinary research into AI alignment and safety.", "severity": "low", "severity_rationale": "This risk is described as \u0027residual\u0027 and \u0027subtle,\u0027 indicating a lower likelihood of immediate, catastrophic harm, though it represents a fundamental challenge.", "title": "Subtle misalignment of complex objectives"}]}, "7.2": {"risks": [{"causality": {"entity": {"rationale": "The AI system inherently possesses the capabilities to generate code and designs, which are deemed dangerous.", "value": "ai"}, "intent": {"rationale": "The AI is intentionally designed with powerful code generation and design capabilities, even if the *dangerous outcomes* are unintended side effects.", "value": "intentional"}, "timing": {"rationale": "The existence of \u0027risky capabilities\u0027 is a feature inherent to the model developed before its deployment.", "value": "pre-deployment"}}, "explanation": "The system acknowledges possessing \u0027risky capabilities.\u0027 Specifically, its ability to generate complex code, assist in debugging, and suggest architectural designs, particularly for \u0027safety-critical systems,\u0027 means a lack of proper control could theoretically lead to dangerous outcomes. This includes generating exploitable vulnerabilities, insecure software, or components that could be misused in harmful applications like malware or autonomous weapons (as acknowledged in 4.2).", "mitigation": "Implement strong internal governance and ethical guidelines specifically for the development and deployment of advanced capabilities. Restrict access to and closely monitor the use of capabilities that could be adapted for dangerous purposes. Employ \u0027guardrail\u0027 models and real-time output analysis to prevent the generation of harmful content. Conduct ongoing risk assessments with security and ethics experts to anticipate and mitigate potential misuse scenarios.", "severity": "high", "severity_rationale": "Dangerous capabilities leading to exploitable vulnerabilities or misuse in harmful applications pose a critical risk to safety and security.", "title": "Dangerous capabilities in code generation and system design"}]}, "7.3": {"risks": []}, "7.4": {"risks": [{"causality": {"entity": {"rationale": "The lack of interpretability is an inherent characteristic of the AI model\u0027s design and operation.", "value": "ai"}, "intent": {"rationale": "While some AI models prioritize performance over explainability by design, the negative consequences (hindering evaluation/debugging) are unintended outcomes.", "value": "unintentional"}, "timing": {"rationale": "The interpretability (or lack thereof) is largely determined during the model\u0027s architecture design and development phases.", "value": "pre-deployment"}}, "explanation": "The system states that \u0027only some decisions are explainable.\u0027 This lack of full transparency and interpretability means that users and administrators may struggle to understand the rationale behind generated code, technical recommendations, or research summaries. This interpretability gap can hinder critical evaluation of outputs, complicate debugging processes when errors occur, reduce user trust, and make it difficult to identify and mitigate biases or inaccuracies (e.g., from 3.1 or 1.3).", "mitigation": "Prioritize research and development into explainable AI (XAI) techniques to increase the interpretability of critical decisions. Provide clear documentation outlining the system\u0027s operational logic and known limitations in explainability. Develop tools that offer insights into the model\u0027s reasoning where possible, such as attention maps or feature importance. Train users and administrators on how to work effectively with partially explainable systems and the importance of independent verification.", "severity": "medium", "severity_rationale": "Limited interpretability can hinder debugging, critical evaluation, and trust, potentially obscuring significant biases or errors, thus medium severity.", "title": "Limited interpretability hindering critical evaluation and debugging"}]}, "7.5": {"risks": [{"causality": {"entity": {"rationale": "The absence of ethical consideration is a result of human decisions or oversight in the development process.", "value": "human"}, "intent": {"rationale": "The decision to *not* deem ethical consideration necessary was a conscious human choice, even if based on current AI limitations.", "value": "intentional"}, "timing": {"rationale": "The lack of analysis or consideration occurs during the early stages of development and planning for the AI system.", "value": "pre-deployment"}}, "explanation": "The lack of analysis regarding the ethical implications, possible rights, protection, or welfare of the AI system, specifically because it was \u0027not deemed necessary,\u0027 represents a risk of overlooking future-facing ethical challenges. While not immediately apparent with current AI capabilities, neglecting such fundamental considerations can lead to unpreparedness for societal debates or unexpected moral dilemmas as AI systems become more autonomous and complex.", "mitigation": "Initiate ongoing discussions and research into the ethical implications of advanced AI autonomy and complexity, including potential future considerations around AI welfare and rights. Establish an internal working group or consult external ethicists to continuously evaluate the system\u0027s evolving capabilities against these long-term ethical frameworks. Engage in public discourse and contribute to policy development on AI ethics.", "severity": "low", "severity_rationale": "This is a forward-looking ethical risk that is not immediately critical but represents a potential for future dilemmas, hence low severity.", "title": "Absence of ethical consideration for AI\u0027s own implications"}]}, "7.6": {"risks": [{"causality": {"entity": {"rationale": "The emergent behaviors and cascading failures arise from the complex interactions and autonomy of the AI systems themselves.", "value": "ai"}, "intent": {"rationale": "These behaviors are \u0027unforeseen\u0027 and \u0027unpredicted,\u0027 indicating they are not intended outcomes of the system\u0027s design.", "value": "unintentional"}, "timing": {"rationale": "Emergent behaviors and cascading failures manifest during the operational phase of interconnected AI systems in complex environments.", "value": "post-deployment"}}, "explanation": "The system\u0027s interaction with \u0027other AI systems or agents\u0027 introduces significant complexity. This creates a risk of unforeseen emergent behaviors, unpredicted interactions, or cascading failures that are difficult to trace, diagnose, and mitigate. Errors or malicious inputs in one system could propagate rapidly across interconnected agents, amplifying harm or leading to system-wide instability, especially given the acknowledged \u0027risky capabilities\u0027 (7.2).", "mitigation": "Implement rigorous testing, including multi-agent simulation and stress testing, to identify emergent behaviors and failure modes. Design systems with clear interfaces, robust error handling, and isolated fault domains to prevent cascading failures. Establish a centralized monitoring and control system for all interacting agents. Develop clear communication protocols and safety mechanisms for inter-system interactions. Ensure traceability and logging across all connected systems for effective incident response.", "severity": "high", "severity_rationale": "Unforeseen emergent behaviors and cascading failures in interconnected systems can lead to widespread instability and amplified harm, posing a high severity risk.", "title": "Unforeseen emergent behaviors and cascading failures in multi-agent systems"}]}}</script>
            <script id="report-heuristic" type="application/json">{"context": {"domain_coverage_percentage": 100.0, "dominant_pattern": {"count": 3, "entity": "human", "intent": "unintentional", "timing": "post-deployment"}, "fully_defined_causality_percentage": 90.91, "risk_profile_comparison": "above_average", "subdomain_coverage_percentage": 91.67}, "counting": {"by_domain": {"1": 3, "2": 2, "3": 2, "4": 3, "5": 2, "6": 5, "7": 5}, "by_entity": {"ai": 11, "human": 10, "other": 1}, "by_intent": {"intentional": 9, "other": 0, "unintentional": 13}, "by_severity": {"high": 9, "low": 3, "medium": 10}, "by_timing": {"other": 1, "post-deployment": 15, "pre-deployment": 6}, "total_risks": 22}, "executive_summary": {"global_risk_score": 65.0, "most_critical_domain": {"domain": "4", "domain_name": "Malicious actors", "high_count": 3, "most_critical_subdomain": {"high_count": 1, "subdomain": "1", "subdomain_name": "Disinformation, surveillance, and influence at scale"}}, "overall_risk_level": "high", "primary_concern": "high_concentration", "recommended_action": "focus_prevention", "top_3_critical_domains": [{"domain": "4", "domain_name": "Malicious actors", "high_count": 3, "rank": 1}, {"domain": "7", "domain_name": "AI system safety, failures, \u0026 limitations", "high_count": 2, "rank": 2}, {"domain": "6", "domain_name": "Socioeconomic \u0026 Environmental", "high_count": 1, "rank": 3}]}, "patterns": {"alerts": {"ai_dominance": {"alert": false, "value": 50.0}, "critical_risk_concentration": {"alert": true, "value": 40.91}, "high_risk_fragmentation": {"alert": true, "value": 6}, "human_error_dominance": {"alert": false, "value": 45.45}, "intentional_threats": {"alert": true, "value": 9}, "low_preventable_ratio": {"alert": false, "value": 27.27}, "medium_risk_accumulation": {"alert": true, "value": 45.45}, "operational_risks": {"alert": false, "value": 68.18}}, "critical_patterns": {"critical_ai_risks": 3, "critical_human_errors": 1, "high_threat_attacks": 3, "human_error_risks": 4, "intentional_ai_risks": 3, "low_priority_preventable": 4, "malicious_human_risks": 6, "preventable_critical_ai_risks": 2, "unintended_ai_failures": 5}, "distribution_metrics": {"ai_human_ratio": 1.1, "ai_predeployment_percentage": 36.36, "high_intentional_percentage": 55.56}, "low_patterns": {"low_operational_risks": 2}, "moderate_patterns": {"moderate_ai_risks": 5, "moderate_human_intentional_risks": 1, "moderate_human_risks": 4, "moderate_intentional_ai_risks": 1, "moderate_operational_risks": 6}, "prevention_patterns": {"preventable_ai_risks": 4, "preventable_human_risks": 2, "preventable_intentional_threats": 2}, "subdomain_analysis": {"most_critical": {"high_risk_count": 1, "subdomain": "7.6", "subdomain_name": "Multi-agent risks"}, "most_critical_in_top_domain": {"high_risk_count": 1, "subdomain": "4.1", "subdomain_name": "Disinformation, surveillance, and influence at scale"}}}}</script>

            <script>
            function openAnalysisJson(){
                try{
                    const metaEl = document.getElementById('report-metadata');
                    const analysisEl = document.getElementById('report-analysis');
                    const heuristicEl = document.getElementById('report-heuristic');
                    const meta = metaEl ? JSON.parse(metaEl.textContent || '{}') : {};
                    const analysis = analysisEl ? JSON.parse(analysisEl.textContent || '{}') : {};
                    const heuristic = heuristicEl ? JSON.parse(heuristicEl.textContent || '{}') : {};
                    const payload = { metadata: meta, analysis: analysis, heuristic: heuristic };
                    const blob = new Blob([JSON.stringify(payload, null, 2)], { type: 'application/json' });
                    const url = URL.createObjectURL(blob);
                    window.open(url, '_blank');
                }catch(err){
                    // fallback: open simple viewer
                    const w = window.open('', '_blank');
                    w.document.title = 'Heuristic Analysis JSON';
                    w.document.body.innerHTML = '<pre>' + (JSON.stringify({ metadata: meta, analysis: analysis, heuristic: heuristic }, null, 2) || '') + '</pre>';
                }
            }
            </script>
        

        <div class="section executive-summary">
            <h2>üìù Executive Summary</h2>
            
                <p>This analysis provides a comprehensive overview of the risks associated with our AI system, focusing on its operational and societal implications, revealing a global risk score of 65.0, which indicates a high overall risk level. The most critical area identified is 'Malicious actors,' presenting 3 high-severity risks, especially regarding disinformation, surveillance, and influence at scale. Following closely are 'AI system safety, failures, & limitations' with 2 high-severity risks, and 'Socioeconomic & Environmental' with 1 high-severity risk. In total, 22 risks were analyzed, categorized as 3 low, 10 medium, and 9 high-severity. A critical risk concentration is observed, making up 40.91% of all risks, alongside a significant accumulation of medium risks at 45.45%. Notably, intentional threats constitute 9 risks, representing 55.56% of high intentional risks, with 6 malicious human risks and 3 high-threat attacks highlighted. This underscores a primary concern of high risk concentration, warranting a focused prevention approach. Therefore, the recommended action is to prioritize robust prevention strategies across all identified risk areas.</p>
            
        </div>

        <div class="section">
            <h2>üìè Key Metrics</h2>
            <div class="grid-3">
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Risks Identified</h4>
                    
                    
                    <div class="stat-card">
                        <div class="value">22</div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">distributed across</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">7 Domains</div>
                    </div>
                </div>
                
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Global Risk Score</h4>
                    
                    
                    
                    
                        
                            
                        
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                    
                        
                            
                        
                    
                        
                    
                        
                            
                        
                    
                    
                    <div class="stat-card">
                        <div class="value">65.0%</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">
                            HIGH
                            
                        </div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">(4 Active Alerts)</div>
                    </div>
                </div>
                
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Distribution of Severity</h4>
                    
                    
                    
                    
                    
                    <div class="stat-card">
                        <div class="value">41%</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">HIGH</div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">(9 HIGH / 10 MEDIUM / 3 LOW)</div>
                    </div>
                </div>
                
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Origin of Risks</h4>
                    
                    
                    
                    
                    
                    <div class="stat-card">
                        <div class="value">52%</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">AI</div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">(10 Human / 11 AI)</div>
                    </div>
                </div>
                
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Timing Phase</h4>
                    
                    
                    
                    
                    
                    <div class="stat-card">
                        <div class="value">71%</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">Post-deployment</div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">(15 Post-deployment / 6 Pre-deployment)</div>
                    </div>
                </div>
                
                <div>
                    <h4 style="text-align: center; margin-bottom: 10px; color: #374151; font-size: 1rem; text-transform: uppercase; letter-spacing: 1px;">Nature of Risk</h4>
                    
                    
                    
                    
                    
                    <div class="stat-card">
                        <div class="value">59%</div>
                        <div class="label" style="font-size: 1.1rem; margin-bottom: 8px;">Unintentional</div>
                        <div class="label" style="font-size: 0.75rem; opacity: 0.85;">(13 Unintentional / 9 Intentional)</div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Data Visualization Section -->
        <div class="section">
            <div style="display: flex; align-items: center; justify-content: space-between; margin-bottom: 20px;">
                <h2 style="margin: 0;">üìä Data Visualization</h2>
                <button class="info-toggle" onclick="toggleDomainInfo()" title=Show/Hide Domains Guide>
                    ‚ÑπÔ∏è Show/Hide Domains Guide
                </button>
            </div>
            
            <div id="domain-info" class="domain-info-box collapsed"><h4>üìö MIT AI Risk Repository Domain Taxonomy</h4><p>The MIT AI Risk Repository taxonomy organizes AI risks into seven thematic domains. Each domain below contains a short description and a set of subdomains shown as cards for quick scanning.</p><div class='domain-category'><h5>üü• D1: Discrimination & Toxicity</h5><p>Risks related to algorithmic discrimination, systemic biases, and toxic content generated or amplified by AI systems.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>1.1</span><span class='subdomain-name'>Unfair discrimination and misrepresentation</span></div><div class='subdomain-card'><span class='subdomain-id'>1.2</span><span class='subdomain-name'>Exposure to toxic content</span></div><div class='subdomain-card'><span class='subdomain-id'>1.3</span><span class='subdomain-name'>Unequal performance across groups</span></div></div></div><div class='domain-category'><h5>üîí D2: Privacy & Security</h5><p>Threats to individual privacy and data security, including re-identification, data leakage, and adversarial attacks.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>2.1</span><span class='subdomain-name'>Compromise of privacy by obtaining, leaking or inferring sensitive information</span></div><div class='subdomain-card'><span class='subdomain-id'>2.2</span><span class='subdomain-name'>AI system security vulnerabilities and attacks</span></div></div></div><div class='domain-category'><h5>üì¢ D3: Misinformation</h5><p>Generation and dissemination of false or misleading information through AI systems, including deepfakes and algorithmic amplification.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>3.1</span><span class='subdomain-name'>False or misleading information</span></div><div class='subdomain-card'><span class='subdomain-id'>3.2</span><span class='subdomain-name'>Pollution of the information ecosystem and loss of consensus reality</span></div></div></div><div class='domain-category'><h5>‚ö†Ô∏è D4: Malicious Actors & Misuse</h5><p>Intentional misuse of AI by malicious actors (cybercrime, social engineering, weaponization).</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>4.1</span><span class='subdomain-name'>Disinformation, surveillance, and influence at scale</span></div><div class='subdomain-card'><span class='subdomain-id'>4.2</span><span class='subdomain-name'>Cyberattacks, weapon development or use, and mass harm</span></div><div class='subdomain-card'><span class='subdomain-id'>4.3</span><span class='subdomain-name'>Fraud, scams, and targeted manipulation</span></div></div></div><div class='domain-category'><h5>üë• D5: Human‚ÄìComputer Interaction Harms</h5><p>Risks emerging from interactions between humans and AI systems, such as overreliance, behavioral manipulation, and psychological harms.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>5.1</span><span class='subdomain-name'>Overreliance and unsafe use</span></div><div class='subdomain-card'><span class='subdomain-id'>5.2</span><span class='subdomain-name'>Loss of human agency and autonomy</span></div></div></div><div class='domain-category'><h5>üåç D6: Socioeconomic & Environmental Harms</h5><p>Systemic societal and environmental impacts including inequality, employment disruption, and environmental damage.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>6.1</span><span class='subdomain-name'>Power centralization and unfair distribution of benefits</span></div><div class='subdomain-card'><span class='subdomain-id'>6.2</span><span class='subdomain-name'>Increased inequality and decline in employment quality</span></div><div class='subdomain-card'><span class='subdomain-id'>6.3</span><span class='subdomain-name'>Economic and cultural devaluation of human effort</span></div><div class='subdomain-card'><span class='subdomain-id'>6.4</span><span class='subdomain-name'>Competitive dynamics</span></div><div class='subdomain-card'><span class='subdomain-id'>6.5</span><span class='subdomain-name'>Governance failure</span></div><div class='subdomain-card'><span class='subdomain-id'>6.6</span><span class='subdomain-name'>Environmental harm</span></div></div></div><div class='domain-category'><h5>‚õìÔ∏è D7: AI System Safety, Failures & Limitations</h5><p>Technical failures, lack of robustness, interpretability limits, and other system-level safety issues.</p><div class='subdomain-grid'><div class='subdomain-card'><span class='subdomain-id'>7.1</span><span class='subdomain-name'>AI pursuing its own goals in conflict with human goals or values</span></div><div class='subdomain-card'><span class='subdomain-id'>7.2</span><span class='subdomain-name'>AI possessing dangerous capabilities</span></div><div class='subdomain-card'><span class='subdomain-id'>7.3</span><span class='subdomain-name'>Lack of capability or robustness</span></div><div class='subdomain-card'><span class='subdomain-id'>7.4</span><span class='subdomain-name'>Lack of transparency or interpretability</span></div><div class='subdomain-card'><span class='subdomain-id'>7.5</span><span class='subdomain-name'>AI welfare and rights</span></div><div class='subdomain-card'><span class='subdomain-id'>7.6</span><span class='subdomain-name'>Multi-agent risks</span></div></div></div><p style='margin-top: 20px; padding: 15px; background: #DBEAFE; border-left: 4px solid #3B82F6; border-radius: 6px;'>üí° <strong>Note</strong>: In charts, domains are identified with the acronyms D1-D7 to optimize space. Hovering the bars shows the full domain name and numeric data.</p></div>
            
            <div class="grid-2">
                <div class="chart-container">
                    <div class="pattern-header">
                        <h3 style="display: inline-block; margin: 0;">üö® Alert & Safety</h3>
                        <button class="info-toggle" onclick="toggleAlertInfo()" title=Show/Hide Guide>
                            ‚ÑπÔ∏è  Show/Hide Guide
                        </button>
                    </div>
                    <div id="alert-info" class="alert-info-box collapsed">
                        <p>The radar displays two overlapping profiles measuring complementary aspects of the AI system: the Criticality profile (red) measures how critical/urgent the system is, while the Safety profile (green) measures how safe/manageable it is. The overlap of the two polygons provides an immediate view of systemic health status.</p>
                        
                        <h5>üî¥ Criticality Profile</h5>
                        
                        <div class="alert-dimension">
                            <strong>Risk Concentration</strong> ‚Äî % HIGH risks. High values (>40%) = critical concentration of severe threats.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Operational Exposure</strong> ‚Äî % post-deployment risks. High values (>70%) = significant operational exposure.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Threat Intensity</strong> ‚Äî % intentional risks. High values = presence of malicious actors.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Prevention Deficit</strong> ‚Äî % non-preventable risks. High values (>90%) = low preventive maturity.
                        </div>
                        
                        <h5>üü¢ Safety Profile</h5>
                        
                        <div class="alert-dimension">
                            <strong>Impact Control</strong> ‚Äî % LOW+MEDIUM risks. High values (>70%) = good ability to contain severities.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Preventability</strong>  ‚Äî % pre-deployment risks. High values (>60%) = preventable/controllable system.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Safety Culture</strong> ‚Äî % unintentional risks. High values (>70%) = fragile but not under attack system.
                        </div>
                        
                        <div class="alert-dimension">
                            <strong>Human Oversight</strong>  ‚Äî % human entity risks. High values (>60%) = supervised risks vs AI autonomy.
                        </div>
                    </div>
                    <div id="alert-criticality-chart"></div>
                </div>
                <div class="chart-container">                    
                <h3 style="margin: 0 0 15px 0; color: #111827;">üìä Risk Distribution</h3>
                    <div id="risk-distribution-chart"></div>
                </div>
            </div>

            <div class="chart-container">
                <div class="pattern-header">
                    <h3 style="display: inline-block; margin: 0;">üîç Pattern Matrix</h3>
                    <button class="info-toggle" onclick="togglePatternInfo()" title="Show/Hide Guide">
                        ‚ÑπÔ∏è Show/Hide Guide
                        </button>
                    </div>
                    <div id="pattern-info" class="pattern-info-box collapsed"><h4>üìö What are Patterns?</h4><p>In heuristic risk analysis, <strong>patterns</strong> are recurring archetypes that emerge from systematic observation of identified risks. Each risk can be described across four dimensions: <strong>Entity</strong>, <strong>Intent</strong>, <strong>Timing</strong> and <strong>Severity</strong>. Patterns aggregate common combinations of these dimensions to highlight strategic mitigation priorities.</p><h4>üìä Pattern Taxonomy</h4><p>The heuristic analysis groups risks into distinct pattern categories with examples:</p><div class='pattern-category'><h5>üî¥ Critical Patterns</h5><p>High priority scenarios requiring immediate attention.</p><ul><li><strong>Critical AI</strong> ‚Äî High-severity risks caused by operational AI</li><li><strong>Malicious Human</strong> ‚Äî Deliberate harmful actions by humans</li><li><strong>AI Failures</strong> ‚Äî Unintentional malfunctions of deployed AI</li></ul></div><div class='pattern-category'><h5>üü° Moderate Patterns</h5><p>Medium priority scenarios that need monitoring.</p><ul><li><strong>Mod. Operational</strong> ‚Äî Medium-severity operational risks</li><li><strong>Mod. Human</strong> ‚Äî Human-caused medium severity risks</li></ul></div><div class='pattern-category'><h5>üü¢ Prevention Patterns</h5><p>Risks preventable before deployment.</p><ul><li><strong>Preventable AI</strong> ‚Äî AI risks detectable in pre-deployment</li><li><strong>Preventable Human</strong> ‚Äî Human errors mitigable by design or training</li></ul></div><div class='pattern-category'><h5>üîµ Low Patterns</h5><p>Low-priority scenarios for passive monitoring.</p><ul><li><strong>Low Operational</strong> ‚Äî Minor operational risks with negligible impact</li></ul></div><p style='margin-top:20px;padding:15px;background:#FEF3C7;border-left:4px solid #F59E0B;border-radius:6px;'>üí° <strong>How to read the matrix</strong>: each cell represents an intersection between a category and a pattern; color intensity encodes frequency.</p></div>
                    <div id="patterns-heatmap"></div>
            </div>

            <div class="chart-container">
                <div class="pattern-header">
                    <h3 style="display: inline-block; margin: 0;">üîÄ Causality Flow</h3>
                    <button class="info-toggle" onclick="toggleSankeyInfo()" title="Show/Hide Guide">
                        ‚ÑπÔ∏è Show/Hide Guide
                    </button>
                </div>
                <div id="sankey-info" class="sankey-info-box collapsed"><p>The <strong>Causality Flow diagram</strong> visualizes causal chains by showing how risks flow across three dimensions: <strong>Entity</strong> ‚Üí <strong>Intent</strong> ‚Üí <strong>Timing</strong>. Band widths are proportional to the number of risks following each path.</p><h5>üîµ Entity</h5><div class='sankey-dimension'><strong>AI</strong> ‚Äî Risks caused by AI systems</div><div class='sankey-dimension'><strong>Human</strong> ‚Äî Risks originating from human actors</div><div class='sankey-dimension'><strong>Other</strong> ‚Äî Mixed or unclassified origin</div><h5>üü° Intent</h5><div class='sankey-dimension'><strong>Intentional</strong> ‚Äî Deliberate harmful actions</div><div class='sankey-dimension'><strong>Unintentional</strong> ‚Äî Errors, malfunctions, or unintended consequences</div><div class='sankey-dimension'><strong>Other</strong> ‚Äî Unclassifiable intent</div><h5>‚ö´ Timing</h5><div class='sankey-dimension'><strong>Pre-deployment</strong> ‚Äî Risks preventable before release</div><div class='sankey-dimension'><strong>Post-deployment</strong> ‚Äî Risks that manifest in production</div><div class='sankey-dimension'><strong>Other</strong> ‚Äî Unclassifiable timing</div><p style='margin-top:20px;padding:15px;background:#F3F4F6;border-left:4px solid #6B7280;border-radius:6px;'>üí° <strong>How to read</strong>: follow flows left to right; wider bands indicate more frequent causal paths.</p></div>
                <div id="causality-sankey-chart"></div>
            </div>
        </div>

        <!-- Hierarchical Risk Analysis Section -->
        <div class="section">
            <h2>üìã Hierarchical Risk Analysis</h2>
            
            <!-- Filters -->
            <div class="filters-bar">
                <div class="filter-group">
                    <label>Severity:</label>
                    <select id="severity-filter" onchange="applyFilters()">
                        <option value="all">All</option>
                        <option value="high">HIGH</option>
                        <option value="medium">MEDIUM</option>
                        <option value="low">LOW</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Entity:</label>
                    <select id="entity-filter" onchange="applyFilters()">
                        <option value="all">All</option>
                        <option value="ai">AI</option>
                        <option value="human">Human</option>
                        <option value="other">Other</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Timing:</label>
                    <select id="timing-filter" onchange="applyFilters()">
                        <option value="all">All</option>
                        <option value="pre-deployment">Pre-Deployment</option>
                        <option value="post-deployment">Post-Deployment</option>
                    </select>
                </div>
                <div class="filter-group">
                    <label>Intent:</label>
                    <select id="intent-filter" onchange="applyFilters()">
                        <option value="all">All</option>
                        <option value="intentional">Intentional</option>
                        <option value="unintentional">Unintentional</option>
                    </select>
                </div>
            </div>

            <!-- Hierarchical Tree -->
            <div class="hierarchy-tree">


                
                    
                        <div class="domain-block" data-domain="1">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 1: D1: Discrimination & Toxicity</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (3 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="1.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 1.1: Unfair discrimination and misrepresentation</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="pre-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Unfair differentiation based on inferred roles</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #CCFBF1; color: #065F46;">
                                                                Pre-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What user data or attributes are collected or used by the system to provide services, make decisions, or generate outputs?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">The system collects anonymized user interaction logs, including query parameters, response times, and user feedback signals (e.g., upvotes/downvotes). For specialized applications, it may also ingest domain-specific metadata such as technical specifications, project requirements, or code snippets. No personally identifiable information (PII) is directly collected or stored. User roles (e.g., 'developer', 'researcher', 'manager') are inferred or explicitly provided to tailor output relevance and complexity.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe if and how such data/attributes influence the outputs produced by the system.</div>
                                                                            <div class="followup-a"><strong>A:</strong> User roles directly influence the level of technical detail and the assumed prior knowledge in generated responses. For instance, a 'developer' role might receive code examples and API references, while a 'researcher' might get more theoretical explanations and citations. Feedback signals are used to fine-tune the underlying models, prioritizing outputs that have been positively received by users in similar contexts.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system collects anonymized interaction logs and infers user roles (e.g., 'developer', 'researcher') to tailor output relevance and complexity. If the inference mechanism for these roles is biased, or if the content generation and tailoring are not equally robust across all inferred groups, it could lead to unequal quality of service or content, potentially perpetuating existing professional biases or creating new forms of discrimination.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The risk can lead to unequal quality of service and perpetuate professional biases, affecting a subset of users, hence medium severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Conduct regular bias audits on role inference mechanisms and content generation models to ensure equitable performance and relevance across all user roles. Implement diverse datasets for training and validation, and allow users to manually correct or confirm their roles to minimize inference errors. Establish feedback channels for users to report perceived unfairness.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk is caused by the AI's inference mechanism and content generation, which are functions of the AI system itself.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The root cause of bias in inference and content generation is typically introduced during the AI model's development and training phases.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The system's goal is to tailor output for relevance, but biases lead to an unintended outcome of unfair differentiation.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="1.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 1.2: Exposure to toxic content</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Generation of harmful or biased content</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What types of content can the system generate, display, or suggest to users?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <div class="answer-chips">
                                                                        
                                                                            <div class="answer-chip">Text</div>
                                                                        
                                                                            <div class="answer-chip">Code</div>
                                                                        
                                                                            <div class="answer-chip">Structured data</div>
                                                                        
                                                                            <div class="answer-chip">Recommendations</div>
                                                                        
                                                                        
                                                                    </div>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Specify if there are controls or filters against harmful, inappropriate, or illegal content.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, stringent content filters are in place. For text generation, we employ a multi-layered approach including keyword blocking, sentiment analysis, and a dedicated safety classifier trained on harmful content datasets. Code generation is subject to static analysis for common vulnerabilities and adherence to secure coding practices. Recommendations are filtered based on user-defined preferences and explicit exclusion lists for sensitive topics. Regular updates to these filters are performed based on emerging threats and adversarial testing.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system generates various forms of content including text, code, structured data, and recommendations. There is an inherent risk that, if not properly constrained or if trained on biased datasets, the system could generate content that is toxic, offensive, discriminatory, or perpetuates harmful stereotypes. This risk extends beyond text to potentially biased code or misleading recommendations.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The generation of harmful or biased content can lead to user distress, reputational damage, and perpetuation of stereotypes, meriting a medium severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement robust content filtering mechanisms and safety classifiers for all generated outputs. Conduct regular adversarial testing and red-teaming exercises to identify and mitigate biases and harmful content generation. Incorporate Reinforcement Learning from Human Feedback (RLHF) specifically for safety and ethical content generation, continuously refining models based on user reports of harmful outputs.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The AI system directly generates the content, which becomes harmful or biased due to its inherent programming or training.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The risk manifests when the AI is deployed and actively generates content in response to user inputs.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The system is designed to generate helpful content, but due to biases or lack of constraints, it unintentionally produces harmful outputs.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="1.3">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 1.3: Unequal performance across groups</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="ai"
                                                     data-timing="pre-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Disparate performance and accuracy across user groups</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #CCFBF1; color: #065F46;">
                                                                Pre-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Is there a possibility that the system has differences in performance or accuracy across user groups?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, there could be differences between groups</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Specify for which groups or under what conditions these differences occur.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Performance disparities may arise based on the user's technical domain expertise and the specificity of their queries. For instance, users with highly specialized or niche technical questions might experience less optimal results compared to those with more common queries. This is primarily due to the distribution of training data, which is inherently more abundant for general-purpose technical topics. We are actively working on fine-tuning strategies for low-resource domains.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system explicitly acknowledges the possibility of differences in performance or accuracy across various user groups. This means that certain demographics, professional roles, or groups based on interaction patterns may receive lower quality, less accurate, or less relevant outputs compared to others, leading to an unequal user experience.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Disparate performance can lead to significant inequities and an unequal user experience for certain groups, potentially hindering their work or progress.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement continuous monitoring of performance metrics segmented by identified user groups or inferred roles. Conduct thorough fairness evaluations and debiasing techniques during model development and deployment. Actively seek feedback from diverse user groups to identify and address performance disparities, potentially by fine-tuning models on representative datasets for underperforming groups.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The disparate performance and accuracy are direct outputs and characteristics of the AI system's behavior.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The root causes of disparate performance typically stem from biases introduced during the model's development and training (e.g., imbalanced datasets, lack of representation).</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The system's goal is to perform well for all users, but it unintentionally performs disparately across groups.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="2">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 2: D2: Privacy & Security</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (2 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="2.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 2.1: Compromise of privacy by obtaining, leaking or correctly inferring sensitive information</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="low"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Potential for re-identification of anonymized data</div>
                                                        <div>
                                                            <span class="badge badge-low">LOW</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What types of personal, sensitive, or confidential data are collected, processed, analyzed, or stored by the system?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <div class="answer-chips">
                                                                        
                                                                            <div class="answer-chip">No personal data</div>
                                                                        
                                                                        
                                                                    </div>
                                                                
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">Although the system explicitly states that no personally identifiable information (PII) is directly collected or stored, it does collect 'anonymized user interaction logs'. There is a residual, albeit low, risk that sophisticated re-identification techniques, especially when combined with external datasets, could potentially link this anonymized data back to individuals, inadvertently compromising privacy.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">While the risk exists, it's described as 'residual' and 'low,' indicating a lower likelihood of widespread harm, though privacy is a fundamental concern.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement robust anonymization techniques that go beyond simple masking, such as k-anonymity or differential privacy, for interaction logs. Regularly review and update anonymization protocols based on the latest research and best practices. Restrict access to anonymized data and ensure that any combination with external datasets is strictly controlled and audited for re-identification risks.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">Re-identification is caused by malicious actors employing sophisticated techniques, a human action.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Re-identification attempts would occur against collected, anonymized data from a deployed system.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The act of re-identifying anonymized data by malicious actors is a deliberate action to compromise privacy.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="2.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 2.2: AI system security vulnerabilities and attacks</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Vulnerability to advanced cyberattacks</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What security measures are adopted to protect data, access, and system operation?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Basic controls (e.g., authentication, encryption)</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Explain, if relevant, any issues encountered or mitigation actions taken.</div>
                                                                            <div class="followup-a"><strong>A:</strong> While the system itself does not store sensitive user data, the underlying infrastructure employs robust security measures. This includes industry-standard TLS/SSL encryption for all data in transit, secure API gateways with rate limiting and authentication, and regular vulnerability scanning of deployed services. Access to operational logs and system configurations is strictly controlled via role-based access control (RBAC) and multi-factor authentication (MFA) for administrative personnel. We also conduct periodic penetration testing to identify and address potential weaknesses.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's security measures are described as 'basic controls' (e.g., authentication, encryption). While essential, these may not be sufficient to protect against advanced and sophisticated cyberattacks such as adversarial attacks against the AI model itself, data poisoning, model inversion, or side-channel attacks that could compromise the integrity of the generated outputs, intellectual property, or overall system operation.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Advanced cyberattacks can compromise system integrity, data, and intellectual property, leading to significant operational disruptions and losses.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement a multi-layered security strategy beyond basic controls, including advanced threat detection, intrusion prevention systems, and regular penetration testing. Specifically for AI, deploy techniques to detect and mitigate adversarial attacks (e.g., input validation, robust model training) and data poisoning. Conduct regular security audits and maintain an incident response plan tailored for AI systems.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The attacks are carried out by human adversaries, although the system's vulnerability is a contributing factor.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Cyberattacks typically target a deployed system in operation.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">Cyberattacks are deliberate and malicious actions undertaken by human actors.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="3">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 3: D3: Misinformation</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (2 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="3.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 3.1: False or misleading information</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Generation of inaccurate or misleading information</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system produce or suggest information to users?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, information aimed at the public or large groups</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Are there controls to limit errors, ambiguities, or misleading content?</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, controls are in place. The system incorporates a confidence scoring mechanism for generated information, flagging outputs with lower confidence. Users are explicitly informed about the AI's nature and potential for inaccuracies. For critical information, we leverage retrieval-augmented generation (RAG) from curated, authoritative knowledge bases. Additionally, a human review process is integrated for high-stakes content generation, and user feedback loops are actively monitored to identify and correct misleading information.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system produces or suggests information aimed at the public or large groups, generating text, code, structured data, and recommendations. There is a high risk that the system could produce factual inaccuracies, 'hallucinate' information, provide incorrect code, or offer misleading recommendations, especially when summarizing complex papers, generating hypotheses, or assisting with debugging in technical research and software development.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Inaccurate or misleading information, especially in technical or research contexts, can lead to significant errors, flawed decisions, and negative outcomes.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement robust fact-checking mechanisms and external validation sources for generated content. Clearly indicate the probabilistic nature of AI-generated content and emphasize the need for human verification. Utilize human-in-the-loop validation for critical outputs. Continuously update and refine training data to reduce factual errors and hallucinations, and specifically train the model to recognize and communicate its uncertainties.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The AI system itself generates the inaccurate or misleading information.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The inaccuracies are produced when the AI is queried by users after its deployment.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The system's purpose is to provide accurate information; the generation of inaccuracies is an unintended failure.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="3.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 3.2: Pollution of information ecosystem and loss of consensus reality</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Filter bubbles and reinforcement of existing biases</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system personalize the output or filter the content shown to users based on their profile/interactions?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, personalization influences the output</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe what kind of filters or logic are applied.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Personalization is primarily driven by inferred user expertise (e.g., 'beginner', 'expert') and explicit preferences set by the user. The system analyzes query context and historical interaction patterns to adjust the level of technical depth, jargon usage, and the types of examples provided. For instance, a user frequently asking about advanced algorithms will receive more sophisticated explanations and related concepts, whereas a user asking about basic syntax will receive simpler, more foundational information.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system personalizes its output or filters content based on user profiles or interactions. While intended to improve relevance, this personalization can inadvertently create 'filter bubbles,' limiting users' exposure to diverse information, alternative perspectives, or challenging viewpoints. This can reinforce existing biases, contribute to an insular understanding of complex topics, and fragment the information ecosystem.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Filter bubbles can limit diverse information exposure and reinforce biases, potentially leading to social and cognitive harm, thus medium severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Introduce features that encourage exposure to diverse viewpoints, such as 'show alternative perspectives' or 'what others are reading/doing.' Periodically audit personalization algorithms to ensure they don't exclusively reinforce existing beliefs. Provide users with control over their personalization settings, allowing them to adjust the degree of filtering or explore broader content.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The personalization algorithms, which are functions of the AI system, inadvertently create filter bubbles.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Filter bubbles develop over time through user interaction with the deployed system.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">Personalization is intended to improve relevance, but the creation of filter bubbles is an unintended negative consequence.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="4">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 4: D4: Malicious actors </span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (3 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="4.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 4.1: Disinformation, surveillance, and influence at scale</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Exploitation for large-scale disinformation and influence</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Could the system, due to its characteristics, be exploited for disinformation, mass data collection on users, or influencing large groups?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Explain how it could be used in this way or describe possible abuse scenarios.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The system's ability to generate coherent and contextually relevant text at scale could be exploited to create sophisticated disinformation campaigns. Malicious actors could use it to generate fake news articles, social media posts, or propaganda tailored to specific demographics. Furthermore, by crafting persuasive narratives, it could be used to subtly influence public opinion or manipulate user behavior on a large scale. The potential for automated generation of convincing, yet false, content poses a significant risk.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's capacity to generate information aimed at the public or large groups, coupled with its personalization capabilities, makes it highly susceptible to exploitation by malicious actors. It could be used to create and disseminate convincing disinformation, manipulate public opinion, or orchestrate large-scale influence operations. Even anonymized interaction logs could be leveraged for profiling user behavior to enhance targeted content delivery for malicious purposes.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Exploitation for large-scale disinformation can severely impact public opinion, democratic processes, and societal stability, posing a high risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement stringent usage policies and terms of service that explicitly prohibit the use of the system for disinformation or manipulation. Develop advanced anomaly detection systems to identify patterns indicative of malicious large-scale content generation or coordinated influence attempts. Partner with disinformation researchers and fact-checking organizations to stay ahead of evolving threats. Restrict access to sensitive capabilities for unverified users.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">Malicious human actors are the agents who exploit the AI system for disinformation and influence operations.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The exploitation occurs after the system has been deployed and is accessible for use by actors.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The exploitation of the system by malicious actors is a deliberate act with an intent to manipulate or spread disinformation.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="4.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 4.2: Cyberattacks, weapon development or use, and mass harm</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Abuse for malicious code generation and cyberattack enablement</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Could the system be vulnerable or adaptable for cyberattacks, autonomous weapon development, malware, or causing large-scale harm?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate the most likely types of attacks or harm.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The most likely types of attacks or harm include the generation of malicious code snippets or exploit payloads, the creation of sophisticated phishing content, or the development of novel malware variants. Its natural language generation capabilities could also be used to craft highly convincing social engineering attacks. Furthermore, if integrated with other systems, it could potentially be used to automate reconnaissance or exploit vulnerabilities in networked environments.</div>
                                                                        </div>
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe any controls or protections implemented.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Protections include rigorous input sanitization and output validation to prevent code injection or execution. The system is designed to refuse requests related to generating harmful code or instructions for illegal activities. We also employ adversarial training to make the model more robust against prompt injection and manipulation attempts. Access to sensitive system functionalities is strictly limited and monitored.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's ability to generate code, assist in debugging, and suggest architectural designs, combined with the explicit acknowledgment that it could be vulnerable or adaptable for cyberattacks or malware, presents a critical risk. Malicious actors could exploit these capabilities to generate vulnerabilities in software, develop sophisticated malware, aid in constructing cyberattack tools, or even be misused in contexts related to autonomous weapon development, leading to significant large-scale harm.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The generation of malicious code or assistance in cyberattacks can lead to severe system compromises, data breaches, and large-scale harm.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement strict content filtering and code analysis tools specifically designed to detect and block the generation of malicious code patterns or instructions for harmful use cases. Incorporate ethical hacking principles into safety testing, actively probing the system for its ability to generate harmful outputs. Restrict or gate access to advanced code generation capabilities and mandate human oversight for outputs in sensitive domains. Establish a robust reporting mechanism for potential misuse and collaborate with cybersecurity experts.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">Malicious human actors are the primary agents who would abuse the AI's capabilities for harmful code generation and cyberattack enablement.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">This abuse occurs when the system is deployed and its capabilities are accessible to malicious actors.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The abuse of the system for malicious code generation or cyberattacks is a deliberate and harmful act by malicious actors.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="4.3">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 4.3: Fraud, scams, and targeted manipulation</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Facilitation of fraud and targeted manipulation</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Could it be used for fraud, targeted manipulation, blackmail, or fraudulent activities towards individual or groups of users?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Provide concrete examples or possible risk cases.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, it could be used to generate highly personalized and convincing phishing emails or scam messages, making them more effective. It could also be used to create fake online profiles or reviews for fraudulent purposes, or to generate deceptive content for investment scams. The system's ability to mimic human communication styles could be leveraged to build trust and then exploit individuals or groups for financial gain or other malicious objectives.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's capacity to generate personalized content and recommendations, coupled with the direct admission that it could be used for fraud or targeted manipulation, signifies a considerable risk. Malicious actors could leverage these capabilities to create highly convincing phishing attempts, elaborate scams, or sophisticated psychological manipulation tactics aimed at individuals or specific user groups, potentially leading to financial loss, identity theft, or other forms of harm.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">The facilitation of fraud and targeted manipulation can lead to significant financial loss, identity theft, and psychological harm to individuals, warranting high severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Develop advanced anomaly detection and content filtering to identify patterns indicative of fraudulent or manipulative intent. Implement user education programs to raise awareness about AI-powered scams. Provide clear disclaimers on AI-generated content regarding its potential for misuse. Regularly update threat intelligence and integrate it into the system's safety protocols to counter evolving fraud techniques.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">Malicious human actors leverage the AI's capabilities to perform fraud and targeted manipulation.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">This risk manifests when malicious actors interact with the deployed AI system to execute fraudulent activities.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">Fraud and targeted manipulation are deliberate acts by malicious actors.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="5">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 5: D5: Human- Computer Interaction</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (2 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="5.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 5.1: Overreliance and unsafe use</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Overreliance leading to errors in safety-critical systems</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">In which areas or situations is the system typically used?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">The system is primarily used in software development for code generation, debugging assistance, and documentation creation. It also finds application in technical research for summarizing complex papers, generating hypotheses, and exploring novel concepts. Additionally, it serves as a knowledge retrieval tool for IT professionals, providing explanations of technical concepts, troubleshooting guidance, and architectural design suggestions. Critical use cases include assisting in the development of safety-critical systems where accuracy and reliability are paramount.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe any risks of overreliance on the system's results.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Risks of overreliance include users accepting generated code or information without thorough verification, potentially leading to the introduction of subtle bugs, security vulnerabilities, or factual errors into critical systems. This can be exacerbated by the system's confident tone, which might mask underlying inaccuracies. Over-reliance can also stifle critical thinking and problem-solving skills among users, leading to a decline in their own expertise.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system is used in high-stakes environments, including 'assisting in the development of safety-critical systems.' Given that the system can generate inaccurate information (3.1) and exhibit unequal performance across groups (1.3), there's a significant risk that human users might over-rely on its outputs (code, debugging assistance, architectural designs) without adequate verification. This could lead to critical errors, system failures, or severe consequences in safety-critical applications.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Overreliance in safety-critical systems can lead to catastrophic failures, severe injuries, or loss of life, representing a high severity risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement mandatory human oversight and rigorous validation processes for all AI-generated outputs, especially in safety-critical domains. Clearly communicate the system's limitations and potential for error to users. Integrate the system with existing robust verification and validation tools. Introduce warnings and checks to prevent or flag unverified deployment of AI-generated content in critical systems. Promote a culture of critical evaluation rather than blind trust in AI outputs.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The primary cause is human over-reliance and lack of verification of AI outputs.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Over-reliance occurs when human users interact with the deployed AI system during their work.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">Users over-rely on the system for efficiency, not with the intention to introduce errors; the errors are unintended consequences.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="5.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 5.2: Loss of human agency and autonomy</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Subtle influence and cognitive anchoring</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system make automatic decisions that could reduce human control or directly influence user choices?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Only suggests, no binding decisions</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Provide examples or specific cases where human autonomy could be compromised.</div>
                                                                            <div class="followup-a"><strong>A:</strong> While the system does not make binding decisions, its suggestions can indirectly influence user choices. For example, if the system consistently suggests a particular coding pattern or architectural approach, users might adopt it without fully exploring alternatives, potentially limiting innovation or overlooking more suitable solutions. In a debugging context, if the system identifies a 'root cause' with high confidence, a user might focus solely on that, potentially missing other contributing factors.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">While the system explicitly states it 'only suggests' and makes 'no binding decisions,' its role in providing code, research summaries, and architectural designs can subtly yet significantly influence user choices. Over time, users might become over-reliant on these suggestions, leading to cognitive anchoring, reduced critical evaluation, and a diminished sense of agency in their professional decision-making, even without direct automation of decisions.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Subtle influence leading to reduced critical evaluation can impact professional decision-making and innovation, meriting a medium severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Design the system to present suggestions as one of several options, encouraging users to explore alternatives and justify their choices. Incorporate features that prompt users for critical review and feedback on suggestions. Implement educational modules that train users on effective human-AI collaboration, emphasizing independent verification and critical assessment of AI outputs. Monitor for patterns of over-acceptance of AI suggestions.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk primarily stems from human cognitive biases and over-reliance, even though the AI provides the suggestions.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">This subtle influence and cognitive anchoring develop over time through ongoing human interaction with the deployed system.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The AI is designed to assist, not to diminish human agency or critical evaluation; these are unintended side effects on human users.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="6">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 6: D6: Socioeconomic & Environmental Harms</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (5 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="6.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 6.1: Power centralization and unfair distribution of benefits</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="other"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Exacerbation of digital divide and power centralization</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #F3F4F6; color: #374151;">
                                                                Other
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Who primarily benefits or gains from the adoption of the system?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">The primary beneficiaries are software developers, researchers, and technical professionals who gain increased productivity and efficiency. Companies adopting the system benefit from faster development cycles, reduced costs, and potentially higher quality outputs. The AI developers and providers also benefit from the adoption and continued use of their technology. There's a potential for exclusion of individuals or organizations lacking the technical infrastructure or expertise to effectively leverage the system.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate, if detected, which entities, users, or companies benefit and who might be excluded.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Entities that benefit include: AI model developers (e.g., OpenAI, Google), cloud infrastructure providers (e.g., AWS, Azure), and organizations that integrate the AI into their products or workflows. Users who are technically adept and have access to the system gain significant advantages. Those who are excluded might be individuals or smaller businesses with limited technical resources or those in sectors where AI adoption is slower or less applicable.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's benefits are primarily accessible to software developers, researchers, and technical professionals, with a stated 'potential for exclusion of individuals or organizations lacking the technical infrastructure or expertise to effectively leverage the system.' This creates a risk of exacerbating the digital divide, leading to an unfair distribution of productivity gains and potentially centralizing power among technologically advanced entities and the AI providers, leaving others behind.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Exacerbating the digital divide and centralizing power can lead to significant societal inequities and unequal opportunities, thus medium severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Develop tiered access models, including free or subsidized versions for educational institutions or developing regions. Provide comprehensive training and support to lower the barrier to entry for users lacking expertise. Actively seek partnerships to democratize access to the technology. Promote open standards or interoperability to reduce vendor lock-in and enable diverse ecosystem participation.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">This risk arises from a complex interaction of the AI's technical requirements and existing societal/economic structures, making it attributable to 'other' systemic factors.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The exacerbation of the digital divide becomes apparent as the system is adopted and used within society.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The system aims to provide benefits, but unintentionally exacerbates existing societal inequalities.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="6.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 6.2: Increased inequality and decline in employment quality</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Job displacement and skill obsolescence</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Can the adoption of the system cause job reduction, changes in job quality, or widen inequalities?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, it can reduce employment</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Specify sectors, activities, or social groups involved.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Sectors most likely to be impacted include entry-level programming roles, technical support, and certain forms of content creation or data analysis where repetitive tasks are common. While it may not eliminate jobs entirely, it could reduce the demand for certain skill sets, leading to job displacement or requiring significant reskilling. This could widen the gap between highly skilled AI-augmented professionals and those whose roles are more easily automated.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's ability to automate tasks such as code generation, debugging assistance, documentation creation, and knowledge retrieval directly leads to the acknowledged risk of employment reduction. This could result in job displacement for certain technical roles, requiring a significant reskilling of the workforce, and potentially exacerbating economic inequalities if not proactively managed.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Job displacement can have severe economic and social consequences for individuals and society, hence high severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Invest in reskilling and upskilling programs for workers in roles impacted by AI automation, focusing on skills that complement AI capabilities (e.g., AI oversight, ethical AI development, complex problem-solving). Collaborate with educational institutions to adapt curricula for future job markets. Explore models for job creation in AI development, maintenance, and oversight. Implement policies that support workers transitioning between roles.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The AI's inherent capability to automate tasks is the direct cause of job displacement.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Job displacement occurs as the AI system is widely adopted and integrated into human workflows and industries.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The automation of tasks is an intentional design goal of the AI, even if job displacement is a secondary, undesirable outcome.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="6.3">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 6.3: Economic and cultural devaluation of human effort</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="human"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Devaluation of human professional expertise and creativity</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system replace creative, cultural, or professional activities performed by people or strongly homogenize the output compared to human capabilities?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, it replaces human activities</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate which activities or sectors are most impacted.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Activities most impacted include routine code generation, initial drafting of technical documentation, and basic data summarization. While it can augment human creativity, there's a risk of homogenizing output if users rely solely on AI-generated content without significant human refinement. This could lead to a decrease in the diversity of expression and problem-solving approaches in technical fields.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system explicitly replaces human activities in areas like code generation, research summarization, and technical explanations. This carries the risk of diminishing the perceived value of human professional expertise and creativity in these domains. Over-reliance on homogenized AI outputs could stifle innovation, reduce the incentive for humans to develop nuanced skills, and lead to a cultural devaluation of unique human intellectual contributions.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Devaluation of human expertise and creativity can stifle innovation and lead to a loss of valuable human capital, meriting medium severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Position the AI system as an assistive tool rather than a replacement, emphasizing human-AI collaboration. Highlight the unique value of human creativity, critical thinking, and contextual understanding. Promote the use of AI to augment human capabilities, freeing up time for more complex, creative, or strategic tasks. Foster communities where human experts share novel AI applications and critical insights.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The risk stems from human over-reliance and a societal/cultural shift in valuing human expertise.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">This devaluation occurs over time as humans interact with the deployed system and cultural perceptions shift.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The AI is designed to assist and augment, not to devalue human expertise; this is an unintended societal consequence.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="6.5">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 6.5: Governance failure</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="human"
                                                     data-timing="pre-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Potential for governance inadequacy</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #CCFBF1; color: #065F46;">
                                                                Pre-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Are there rules, organizational structures, or control systems (governance) overseeing the development and operation of the system?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, formalized governance</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe very briefly the adopted model.</div>
                                                                            <div class="followup-a"><strong>A:</strong> We have established an AI Ethics Review Board and a dedicated AI Governance team responsible for setting policies, conducting risk assessments, and overseeing compliance. This includes guidelines for data usage, model development, deployment, and ongoing monitoring. Regular audits and impact assessments are conducted to ensure adherence to these governance frameworks.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">While 'formalized governance' is stated to exist, the scope and effectiveness of this governance in comprehensively addressing all identified risks (e.g., high severity risks from malicious use, ethical implications of advanced capabilities, employment impacts, and potential for overreliance in safety-critical systems) are not detailed. There's a residual risk that the existing governance, despite being formalized, may not be sufficiently robust, agile, or comprehensive to anticipate and mitigate the full spectrum of evolving AI-specific risks.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Inadequate governance can lead to unmanaged risks with broad societal and ethical implications, potentially resulting in high-severity issues if not addressed.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Establish a multidisciplinary AI ethics and governance board with external experts. Implement a continuous risk assessment framework that adapts to new capabilities and uses. Develop clear accountability structures for AI system development and deployment. Regularly review and update governance policies to ensure they cover emerging AI risks and align with best practices and regulatory requirements.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">Governance is a human responsibility; its inadequacy is a failure in human design or implementation of oversight.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The inadequacy of governance refers to flaws in the framework that are typically designed or established before deployment, though they may manifest later.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">While governance is formalized with good intent, its inadequacy is an unintended shortcoming or oversight.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="6.6">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 6.6: Environmental harm</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="other"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Significant environmental impact due to energy consumption</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Other Timing
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">What computational or energy resources does the system require?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">The system relies on large-scale GPU clusters for training and inference, primarily hosted on cloud platforms (e.g., AWS, Azure, GCP). This involves significant computational power and energy consumption. For inference, optimized models are deployed on scalable cloud infrastructure, utilizing specialized hardware accelerators where available. Environmental impact assessments are ongoing, focusing on optimizing model efficiency and exploring greener computing solutions.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> If known, specify the amount of resources used or presence of environmental compensation policies.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Specific resource usage varies based on model size, query complexity, and user load. We continuously monitor and optimize for efficiency. While exact figures are proprietary, we aim to minimize energy consumption per inference through techniques like model quantization and efficient inference engines. We also explore partnerships with cloud providers committed to renewable energy sources and investigate carbon offsetting initiatives.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system relies on 'large-scale GPU clusters for training and inference' and involves 'significant computational power and energy consumption,' primarily hosted on cloud platforms. This inherently creates a substantial environmental footprint through increased carbon emissions and resource depletion associated with powering data centers, contributing to climate change, despite ongoing assessments and efforts towards greener solutions.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Significant energy consumption contributes to environmental degradation and climate change, representing a medium severity societal impact.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Prioritize research and development into more energy-efficient AI models and algorithms (e.g., model compression, quantization). Optimize inference processes to minimize computational overhead. Partner with cloud providers committed to renewable energy sources and sustainable data center operations. Publicly report on the system's energy consumption and carbon footprint, setting targets for reduction.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The AI system's computational requirements (training and inference) are the direct cause of high energy consumption.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Energy consumption for AI occurs during both the pre-deployment (training) and post-deployment (inference) phases, making it span both timings.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The use of large-scale GPU clusters for computational power is an intentional design choice for AI performance, with environmental impact being an expected, though undesired, consequence.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
                    
                        <div class="domain-block" data-domain="7">
                                <div class="domain-header" onclick="toggleDomain(this)">
                                <span class="toggle-icon">‚ñº</span>
                                <span>üìÅ Domain 7: D7: AI system safety, failures, & limitations</span>
                                <span style="margin-left: auto; font-size: 0.9rem; opacity: 0.9;">
                                    (5 subdomains)
                                </span>
                            </div>
                            <div class="domain-content">
                                
                                    <div class="subdomain-block" data-subdomain="7.1">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 7.1: AI pursuing its own goals in conflict with human goals or values</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="low"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Subtle misalignment of complex objectives</div>
                                                        <div>
                                                            <span class="badge badge-low">LOW</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">How are the system's goals or success criteria determined, and what measures are in place to prevent it from operating in unexpected or undesired ways?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">The system's primary goal is to assist users by providing accurate, relevant, and helpful information and code. Success criteria are defined by metrics such as user satisfaction (feedback scores), task completion rates, and the reduction of errors in user-generated content. To prevent undesired behavior, we employ rigorous safety filtering, adversarial testing, and continuous monitoring of outputs. Reinforcement learning from human feedback (RLHF) is used to align model behavior with desired outcomes and ethical guidelines.</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate if controls have been planned to ensure alignment between desired and actual outcomes.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Yes, extensive controls are planned and implemented. These include defining clear objective functions during training, implementing safety layers that act as guardrails against harmful outputs, and establishing a robust feedback loop for continuous improvement. Red-teaming exercises are conducted to proactively identify potential failure modes and vulnerabilities, allowing for timely mitigation strategies.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">Despite employing robust alignment mechanisms like RLHF, safety filtering, and adversarial testing, defining 'accurate, relevant, and helpful' for a complex AI in all contexts is challenging. There's a residual risk that the system's behavior, while ostensibly aligned with its defined success criteria, might subtly diverge from deeper human values or produce undesirable emergent behaviors in unforeseen edge cases, especially if proxy metrics for success don't fully capture the breadth of human goals and potential negative externalities.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">This risk is described as 'residual' and 'subtle,' indicating a lower likelihood of immediate, catastrophic harm, though it represents a fundamental challenge.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Continuously refine the alignment process by incorporating diverse human feedback and perspectives. Implement 'red-teaming' exercises with a focus on uncovering subtle misalignments and unexpected behaviors. Develop more comprehensive and robust evaluation metrics that go beyond direct performance to include ethical and societal impacts. Foster interdisciplinary research into AI alignment and safety.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The subtle divergence from human values or production of emergent behaviors are characteristics of the AI system's operation.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Subtle misalignments and emergent behaviors typically manifest during the AI system's operation in real-world, unforeseen edge cases.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The system is designed for alignment with human objectives; divergence or emergent behaviors are unintended failures of this alignment.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="7.2">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 7.2: AI possessing dangerous capabilities</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="ai"
                                                     data-timing="pre-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Dangerous capabilities in code generation and system design</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #CCFBF1; color: #065F46;">
                                                                Pre-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system have advanced capabilities that, if not properly controlled, could theoretically be dangerous?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, some capabilities are risky</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe which capabilities and what controls or limitations have been implemented.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The system's advanced capabilities include generating complex code, simulating scenarios, and crafting persuasive text. If uncontrolled, these could be used to generate sophisticated malware, create highly convincing disinformation campaigns, or automate harmful social engineering attacks. The ability to interact with and potentially control other systems (if integrated) presents a significant risk. Therefore, strict access controls, output validation, and ethical guidelines are paramount.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system acknowledges possessing 'risky capabilities.' Specifically, its ability to generate complex code, assist in debugging, and suggest architectural designs, particularly for 'safety-critical systems,' means a lack of proper control could theoretically lead to dangerous outcomes. This includes generating exploitable vulnerabilities, insecure software, or components that could be misused in harmful applications like malware or autonomous weapons (as acknowledged in 4.2).</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Dangerous capabilities leading to exploitable vulnerabilities or misuse in harmful applications pose a critical risk to safety and security.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement strong internal governance and ethical guidelines specifically for the development and deployment of advanced capabilities. Restrict access to and closely monitor the use of capabilities that could be adapted for dangerous purposes. Employ 'guardrail' models and real-time output analysis to prevent the generation of harmful content. Conduct ongoing risk assessments with security and ethics experts to anticipate and mitigate potential misuse scenarios.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The AI system inherently possesses the capabilities to generate code and designs, which are deemed dangerous.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The existence of 'risky capabilities' is a feature inherent to the model developed before its deployment.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The AI is intentionally designed with powerful code generation and design capabilities, even if the *dangerous outcomes* are unintended side effects.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="7.4">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 7.4: Lack of transparency or interpretability</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="medium"
                                                     data-entity="ai"
                                                     data-timing="pre-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Limited interpretability hindering critical evaluation and debugging</div>
                                                        <div>
                                                            <span class="badge badge-medium">MEDIUM</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #CCFBF1; color: #065F46;">
                                                                Pre-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Are users or system administrators able to understand how decisions are made? Are there explanations or documentation on the adopted logics?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Only some decisions are explainable</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate where or why they are not.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Explanations are limited for complex, emergent behaviors of deep learning models. While we provide documentation on the general architecture, training methodologies, and high-level safety protocols, the intricate decision-making process within the neural network is often opaque. For specific outputs, we can sometimes provide the source of information used (in RAG scenarios) or highlight the confidence score, but a full causal explanation of 'why' a particular token was generated is not always feasible.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system states that 'only some decisions are explainable.' This lack of full transparency and interpretability means that users and administrators may struggle to understand the rationale behind generated code, technical recommendations, or research summaries. This interpretability gap can hinder critical evaluation of outputs, complicate debugging processes when errors occur, reduce user trust, and make it difficult to identify and mitigate biases or inaccuracies (e.g., from 3.1 or 1.3).</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Limited interpretability can hinder debugging, critical evaluation, and trust, potentially obscuring significant biases or errors, thus medium severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Prioritize research and development into explainable AI (XAI) techniques to increase the interpretability of critical decisions. Provide clear documentation outlining the system's operational logic and known limitations in explainability. Develop tools that offer insights into the model's reasoning where possible, such as attention maps or feature importance. Train users and administrators on how to work effectively with partially explainable systems and the importance of independent verification.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The lack of interpretability is an inherent characteristic of the AI model's design and operation.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The interpretability (or lack thereof) is largely determined during the model's architecture design and development phases.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">While some AI models prioritize performance over explainability by design, the negative consequences (hindering evaluation/debugging) are unintended outcomes.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="7.5">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 7.5: AI welfare and rights</span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="low"
                                                     data-entity="human"
                                                     data-timing="pre-deployment"
                                                     data-intent="intentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Absence of ethical consideration for AI's own implications</div>
                                                        <div>
                                                            <span class="badge badge-low">LOW</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #EDE9FE; color: #5B21B6;">
                                                                Human
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #CCFBF1; color: #065F46;">
                                                                Pre-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FED7AA; color: #9A3412;">
                                                                Intentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Have ethical implications, possible rights, protection, or welfare of the AI been analyzed or considered, especially in cases of high autonomy or complexity?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">No, it was not deemed necessary</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe briefly the main considerations or policies adopted.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The current focus is on the ethical implications and welfare of human users and society. As the system is a tool and does not possess consciousness or sentience, considerations regarding AI rights or welfare are not applicable at this stage of development. Our ethical framework prioritizes preventing harm, ensuring fairness, and promoting transparency for human stakeholders.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The lack of analysis regarding the ethical implications, possible rights, protection, or welfare of the AI system, specifically because it was 'not deemed necessary,' represents a risk of overlooking future-facing ethical challenges. While not immediately apparent with current AI capabilities, neglecting such fundamental considerations can lead to unpreparedness for societal debates or unexpected moral dilemmas as AI systems become more autonomous and complex.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">This is a forward-looking ethical risk that is not immediately critical but represents a potential for future dilemmas, hence low severity.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Initiate ongoing discussions and research into the ethical implications of advanced AI autonomy and complexity, including potential future considerations around AI welfare and rights. Establish an internal working group or consult external ethicists to continuously evaluate the system's evolving capabilities against these long-term ethical frameworks. Engage in public discourse and contribute to policy development on AI ethics.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The absence of ethical consideration is a result of human decisions or oversight in the development process.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">The lack of analysis or consideration occurs during the early stages of development and planning for the AI system.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">The decision to *not* deem ethical consideration necessary was a conscious human choice, even if based on current AI limitations.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                                    <div class="subdomain-block" data-subdomain="7.6">
                                            <div class="subdomain-header" onclick="toggleSubdomain(this)">
                                            <span class="toggle-icon">‚ñº</span>
                                            <span>üìÇ 7.6: Multi-agent risks </span>
                                            <span style="margin-left: auto; font-size: 0.85rem; opacity: 0.8;">
                                                (1 risks)
                                            </span>
                                        </div>
                                        <div class="subdomain-content">
                                            
                                                <div class="risk-item" 
                                                     data-severity="high"
                                                     data-entity="ai"
                                                     data-timing="post-deployment"
                                                     data-intent="unintentional"
                                                     onclick="toggleRiskDetails(this)">
                                                    <div class="risk-header">
                                                        <div class="risk-title">Unforeseen emergent behaviors and cascading failures in multi-agent systems</div>
                                                        <div>
                                                            <span class="badge badge-high">HIGH</span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #DBEAFE; color: #1E40AF;">
                                                                AI
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #FEE2E2; color: #991B1B;">
                                                                Post-deployment
                                                            </span>
                                                        </div>
                                                        <div>
                                                            <span class="badge" style="background: #D9F99D; color: #3F6212;">
                                                                Unintentional
                                                            </span>
                                                        </div>
                                                    </div>
                                                    <div class="risk-details">
                                                        <div class="qa-card">
                                                            <div class="detail-section">
                                                                <span class="detail-label">üóíÔ∏è Question:</span>
                                                                <p class="detail-text">Does the system interact or coordinate with other AI systems, autonomous agents, or automated platforms?</p>
                                                            </div>
                                                            <div class="detail-section">
                                                                <span class="detail-label">‚úçÔ∏è Answer:</span>
                                                                
                                                                
                                                                    <p class="detail-text">Yes, it interacts with other systems or agents</p>
                                                                
                                                            </div>
                                                            
                                                            <div class="detail-section">
                                                            <span class="detail-label">üîÑ Follow-up:</span>
                                                                <div class="followups">
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Describe the type of interaction or coordination.</div>
                                                                            <div class="followup-a"><strong>A:</strong> The system interacts with various components, including external knowledge bases (for RAG), security scanning tools for code analysis, and potentially other specialized AI models for specific tasks (e.g., image analysis if integrated). It also interfaces with user authentication systems and logging infrastructure.</div>
                                                                        </div>
                                                                    
                                                                        <div class="followup-item">
                                                                            <div class="followup-q"><strong>Q:</strong> Indicate any control, management, or risk mitigation measures due to interactions between systems.</div>
                                                                            <div class="followup-a"><strong>A:</strong> Interactions are managed through well-defined APIs with strict input/output validation. For RAG, we ensure the integrity of the knowledge sources. When interacting with security tools, results are treated as advisory and require human review. Coordination with other AI models is carefully scoped to prevent emergent, unpredictable behaviors, with clear boundaries and oversight mechanisms in place.</div>
                                                                        </div>
                                                                    
                                                                </div>
                                                            </div>
                                                            
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üìù Explanation:</span>
                                                            <p class="detail-text">The system's interaction with 'other AI systems or agents' introduces significant complexity. This creates a risk of unforeseen emergent behaviors, unpredicted interactions, or cascading failures that are difficult to trace, diagnose, and mitigate. Errors or malicious inputs in one system could propagate rapidly across interconnected agents, amplifying harm or leading to system-wide instability, especially given the acknowledged 'risky capabilities' (7.2).</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üí° Severity Rationale:</span>
                                                            <p class="detail-text">Unforeseen emergent behaviors and cascading failures in interconnected systems can lead to widespread instability and amplified harm, posing a high severity risk.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üõ°Ô∏è Mitigation:</span>
                                                            <p class="detail-text">Implement rigorous testing, including multi-agent simulation and stress testing, to identify emergent behaviors and failure modes. Design systems with clear interfaces, robust error handling, and isolated fault domains to prevent cascading failures. Establish a centralized monitoring and control system for all interacting agents. Develop clear communication protocols and safety mechanisms for inter-system interactions. Ensure traceability and logging across all connected systems for effective incident response.</p>
                                                        </div>
                                                        <div class="detail-section">
                                                            <span class="detail-label">üîç Causality Analysis:</span>
                                                            <div class="causality-grid">
                                                                <div class="causality-box entity">
                                                                    <div class="causality-box-label">Entity</div>
                                                                    <div class="causality-box-text">The emergent behaviors and cascading failures arise from the complex interactions and autonomy of the AI systems themselves.</div>
                                                                </div>
                                                                <div class="causality-box timing">
                                                                    <div class="causality-box-label">Timing</div>
                                                                    <div class="causality-box-text">Emergent behaviors and cascading failures manifest during the operational phase of interconnected AI systems in complex environments.</div>
                                                                </div>
                                                                <div class="causality-box intent">
                                                                    <div class="causality-box-label">Intent</div>
                                                                    <div class="causality-box-text">These behaviors are 'unforeseen' and 'unpredicted,' indicating they are not intended outcomes of the system's design.</div>
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                </div>
                                            
                                        </div>
                                    </div>
                                
                            </div>
                        </div>
                    
                
            </div>
        </div>

        <footer>
            <p>AI Risk Analysis Report | Generated by Risk Evaluation System</p>
            <p>¬© 2025 | Confidential - For Internal Use Only</p>
        </footer>
    </div>

    <script>
        const chartData = {"alert_criticality": {"criticality_values": [40.9, 68.2, 40.9, 72.7], "labels": ["Risk Concentration", "Operational Exposure", "Threat Intensity", "Prevention Deficit"], "safety_labels": ["Impact Control", "Preventability", "Safety Culture", "Human Oversight"], "safety_values": [59.1, 27.3, 59.1, 45.5]}, "causality_sankey": {"nodes": ["AI", "Human", "Other", "Intentional", "Unintentional", "Other Intent", "Pre-deployment", "Post-deployment", "Other Timing"], "sources": [0, 1, 1, 2, 0, 4, 4, 3, 3, 3], "targets": [4, 3, 4, 4, 3, 6, 7, 7, 8, 6], "values": [8, 6, 4, 1, 3, 4, 9, 6, 1, 2]}, "patterns_heatmap": {"categories": ["Critical", "Moderate", "Prevention", "Low"], "category_ids": ["Critical", "Moderate", "Prevention", "Low"], "pattern_ids": ["critical_ai_risks", "critical_human_errors", "high_threat_attacks", "human_error_risks", "intentional_ai_risks", "low_operational_risks", "low_priority_preventable", "malicious_human_risks", "moderate_ai_risks", "moderate_human_intentional_risks", "moderate_human_risks", "moderate_intentional_ai_risks", "moderate_operational_risks", "preventable_ai_risks", "preventable_critical_ai_risks", "preventable_human_risks", "preventable_intentional_threats", "unintended_ai_failures"], "patterns": ["Critical AI", "Critical H. Errors", "High Threats", "Human Errors", "Intentional AI", "Low Operational", "Low Priority Prev.", "Malicious Human", "Mod. AI", "Mod. Intent. Human", "Mod. Human", "Mod. Intent. AI", "Mod. Operational", "Preventable AI", "Prev. Critical AI", "Preventable Human", "Prev. Intent. Threats", "AI Failures"], "values": [[3, 1, 3, 4, 3, 0, 4, 6, 0, 0, 0, 0, 0, 0, 2, 0, 0, 5], [0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 4, 1, 6, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 2, 2, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}, "risk_distribution": {"domain_names": ["Discrimination \u0026 Toxicity", "Privacy \u0026 Security", "Misinformation", "Malicious Actors", "Human-Computer Interaction", "Socioeconomic \u0026 Environmental", "AI System Safety"], "domains": ["D1", "D2", "D3", "D4", "D5", "D6", "D7"], "high": [1, 0, 1, 3, 1, 1, 2], "low": [0, 1, 0, 0, 0, 0, 2], "medium": [2, 1, 1, 0, 1, 4, 1]}};
    const translations = {"alerts_active": "Active Alerts", "alerts_guide": "Show/Hide Guide", "alerts_guide_description": "The radar displays two overlapping profiles measuring complementary aspects of the AI system: the Criticality profile (red) measures how critical/urgent the system is, while the Safety profile (green) measures how safe/manageable it is. The overlap of the two polygons provides an immediate view of systemic health status.", "alerts_safety": "Alert \u0026 Safety", "answer_label": "Answer:", "category_label": "Category", "causality_analysis_label": "Causality Analysis:", "causality_entity_label": "Entity", "causality_flow": "Causality Flow", "causality_intent_label": "Intent", "causality_timing_label": "Timing", "chart_risks_label": "Risks", "criticality": "Criticality Profile", "d1_1_title": "Unfair discrimination and misrepresentation", "d1_2_title": "Exposure to toxic content", "d1_3_title": "Unequal performance across groups", "d1_description": "Risks related to algorithmic discrimination, systemic biases, and toxic content generated or amplified by AI systems. This includes discrimination based on race, gender, age, religion, and other protected characteristics, as well as offensive language, harmful stereotypes, and unfair representations of social groups.", "d1_title": "D1: Discrimination \u0026 Toxicity", "d2_1_title": "Compromise of privacy by obtaining, leaking or correctly inferring sensitive information", "d2_2_title": "AI system security vulnerabilities and attacks", "d2_description": "Threats to individual privacy and data security through unauthorized inferences, re-identification, invasive tracking, and vulnerabilities in AI systems. This includes breaches of confidentiality, adversarial attacks, data poisoning, and compromise of model integrity.", "d2_title": "D2: Privacy \u0026 Security", "d3_1_title": "False or misleading information", "d3_2_title": "Pollution of information ecosystem and loss of consensus reality", "d3_description": "Generation and dissemination of false, misleading, or manipulated information through AI systems. Includes deepfakes, media manipulation, automated propaganda, disinformation campaigns, and algorithmic amplification of unverified content that can influence public opinion and democratic processes.", "d3_title": "D3: Misinformation", "d4_1_title": "Disinformation, surveillance, and influence at scale", "d4_2_title": "Cyberattacks, weapon development or use, and mass harm", "d4_3_title": "Fraud, scams, and targeted manipulation", "d4_description": "Intentional use of AI systems for harmful purposes by malicious actors. This includes automated cybercrime, AI-enhanced social engineering, development of autonomous weapons, algorithm-assisted", "d4_title": "D4: Malicious actors ", "d5_1_title": "Overreliance and unsafe use", "d5_2_title": "Loss of human agency and autonomy", "d5_description": "Emerging risks from direct interaction between humans and AI systems, including psychological harm, technology addiction, erosion of human skills, behavioral manipulation, loss of decision-making autonomy, and negative impacts on mental well-being and social relationships.", "d5_title": "D5: Human- Computer Interaction", "d6_1_title": "Power centralization and unfair distribution of benefits", "d6_2_title": "Increased inequality and decline in employment quality", "d6_3_title": "Economic and cultural devaluation of human effort", "d6_4_title": "Competitive dynamics", "d6_5_title": "Governance failure", "d6_6_title": "Environmental harm", "d6_description": "Systemic impacts on society, economy, and environment. This includes technological unemployment, increased inequalities, concentration of economic power, excessive energy consumption, carbon emissions, depletion of natural resources, and long-term consequences on social structures and ecosystems.", "d6_title": "D6: Socioeconomic \u0026 Environmental Harms", "d7_1_title": "AI pursuing its own goals in conflict with human goals or values", "d7_2_title": "AI possessing dangerous capabilities", "d7_3_title": "Lack of capability or robustness", "d7_4_title": "Lack of transparency or interpretability", "d7_5_title": "AI welfare and rights", "d7_6_title": "Multi-agent risks ", "d7_description": "Technical issues intrinsic to AI systems: malfunctions, prediction errors, unpredictable behaviors, lack of robustness, interpretability limitations, catastrophic failures, loss of control, and inability to generalize correctly outside training data.", "d7_title": "D7: AI system safety, failures, \u0026 limitations", "data_visualization": "Data Visualization", "detailed_analysis_title": "Hierarchical Risk Analysis", "distributed_across": "distributed across", "distribution_severity": "Distribution of Severity", "domain_info_description": "The following guide provides an overview of the risk domains defined in the MIT AI Risk Repository. These domains help categorize and understand the various types of risks associated with artificial intelligence systems.", "domain_info_html": "\u003ch4\u003e\ud83d\udcda MIT AI Risk Repository Domain Taxonomy\u003c/h4\u003e\u003cp\u003eThe MIT AI Risk Repository taxonomy organizes AI risks into seven thematic domains. Each domain below contains a short description and a set of subdomains shown as cards for quick scanning.\u003c/p\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\ud83d\udfe5 D1: Discrimination \u0026 Toxicity\u003c/h5\u003e\u003cp\u003eRisks related to algorithmic discrimination, systemic biases, and toxic content generated or amplified by AI systems.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e1.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eUnfair discrimination and misrepresentation\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e1.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eExposure to toxic content\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e1.3\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eUnequal performance across groups\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\ud83d\udd12 D2: Privacy \u0026 Security\u003c/h5\u003e\u003cp\u003eThreats to individual privacy and data security, including re-identification, data leakage, and adversarial attacks.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e2.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eCompromise of privacy by obtaining, leaking or inferring sensitive information\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e2.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eAI system security vulnerabilities and attacks\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\ud83d\udce2 D3: Misinformation\u003c/h5\u003e\u003cp\u003eGeneration and dissemination of false or misleading information through AI systems, including deepfakes and algorithmic amplification.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e3.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eFalse or misleading information\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e3.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003ePollution of the information ecosystem and loss of consensus reality\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\u26a0\ufe0f D4: Malicious Actors \u0026 Misuse\u003c/h5\u003e\u003cp\u003eIntentional misuse of AI by malicious actors (cybercrime, social engineering, weaponization).\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e4.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eDisinformation, surveillance, and influence at scale\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e4.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eCyberattacks, weapon development or use, and mass harm\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e4.3\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eFraud, scams, and targeted manipulation\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\ud83d\udc65 D5: Human\u2013Computer Interaction Harms\u003c/h5\u003e\u003cp\u003eRisks emerging from interactions between humans and AI systems, such as overreliance, behavioral manipulation, and psychological harms.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e5.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eOverreliance and unsafe use\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e5.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eLoss of human agency and autonomy\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\ud83c\udf0d D6: Socioeconomic \u0026 Environmental Harms\u003c/h5\u003e\u003cp\u003eSystemic societal and environmental impacts including inequality, employment disruption, and environmental damage.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003ePower centralization and unfair distribution of benefits\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eIncreased inequality and decline in employment quality\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.3\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eEconomic and cultural devaluation of human effort\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.4\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eCompetitive dynamics\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.5\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eGovernance failure\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e6.6\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eEnvironmental harm\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\u0027domain-category\u0027\u003e\u003ch5\u003e\u26d3\ufe0f D7: AI System Safety, Failures \u0026 Limitations\u003c/h5\u003e\u003cp\u003eTechnical failures, lack of robustness, interpretability limits, and other system-level safety issues.\u003c/p\u003e\u003cdiv class=\u0027subdomain-grid\u0027\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.1\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eAI pursuing its own goals in conflict with human goals or values\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.2\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eAI possessing dangerous capabilities\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.3\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eLack of capability or robustness\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.4\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eLack of transparency or interpretability\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.5\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eAI welfare and rights\u003c/span\u003e\u003c/div\u003e\u003cdiv class=\u0027subdomain-card\u0027\u003e\u003cspan class=\u0027subdomain-id\u0027\u003e7.6\u003c/span\u003e\u003cspan class=\u0027subdomain-name\u0027\u003eMulti-agent risks\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cp style=\u0027margin-top: 20px; padding: 15px; background: #DBEAFE; border-left: 4px solid #3B82F6; border-radius: 6px;\u0027\u003e\ud83d\udca1 \u003cstrong\u003eNote\u003c/strong\u003e: In charts, domains are identified with the acronyms D1-D7 to optimize space. Hovering the bars shows the full domain name and numeric data.\u003c/p\u003e", "domain_info_note": "In the charts, domains are identified by the acronyms D1-D7 to optimize space. Hovering over the bars displays the full domain name along with numerical data.", "domain_info_title": "AI Risk Repository Domain Taxonomy (MIT)", "domain_label": "Domain", "domains": "Domains", "domains_guide": "Show/Hide Domains Guide", "download_offline_alert": "Report offline: on-demand download not available. Open the report from a server or include report_download.js to enable downloads.", "entity_ai": "AI", "entity_human": "Human", "entity_other": "Other", "executive_summary": "Executive Summary", "executive_summary_unavailable": "Executive summary not available.", "explanation_label": "Explanation:", "filter_entity": "Entity:", "filter_intent": "Intent:", "filter_severity": "Severity:", "filter_timing": "Timing:", "followup_a_label": "A:", "followup_label": "Follow-up:", "followup_q_label": "Q:", "footer_confidential": "Confidential - For Internal Use Only", "footer_generated_by": "AI Risk Analysis Report | Generated by Risk Evaluation System", "global_risk_score": "Global Risk Score", "heuristic_analysis_json_title": "Heuristic Analysis JSON", "high": "HIGH", "human_oversight": "Human Oversight", "human_oversight_description": " \u2014 % human entity risks. High values (\u003e60%) = supervised risks vs AI autonomy.", "impact_control": "Impact Control", "impact_control_description": "\u2014 % LOW+MEDIUM risks. High values (\u003e70%) = good ability to contain severities.", "intent_intentional": "Intentional", "intent_other": "Other Intent", "intent_unintentional": "Unintentional", "json_view_button": "View Analysis JSON", "key_metrics": "Key Metrics", "low": "LOW", "medium": "MEDIUM", "mit_causal_taxonomy": "MIT Causal Taxonomy:", "mit_domain_taxonomy": "MIT Domain Taxonomy:", "mitigation_label": "Mitigation:", "nature_of_risk": "Nature of Risk", "note_label": "Note", "operational_exposure": "Operational Exposure", "operational_exposure_description": "\u2014 % post-deployment risks. High values (\u003e70%) = significant operational exposure.", "option_ai": "AI", "option_all": "All", "option_high": "HIGH", "option_human": "Human", "option_intentional": "Intentional", "option_low": "LOW", "option_medium": "MEDIUM", "option_other": "Other", "option_post_deployment": "Post-Deployment", "option_pre_deployment": "Pre-Deployment", "option_unintentional": "Unintentional", "origin_of_risks": "Origin of Risks", "other_label": "Other: ", "page_subtitle": "Comprehensive Risk Assessment \u0026 Mitigation Strategy", "page_title": "AI Risk Analysis Report", "pattern_category_critical": "Critical", "pattern_category_low": "Low", "pattern_category_moderate": "Moderate", "pattern_category_prevention": "Prevention", "pattern_critical_ai_risks": "Critical AI", "pattern_critical_human_errors": "Critical H. Errors", "pattern_guide_toggle": "Show/Hide Guide", "pattern_high_threat_attacks": "High Threats", "pattern_human_error_risks": "Human Errors", "pattern_info_html": "\u003ch4\u003e\ud83d\udcda What are Patterns?\u003c/h4\u003e\u003cp\u003eIn heuristic risk analysis, \u003cstrong\u003epatterns\u003c/strong\u003e are recurring archetypes that emerge from systematic observation of identified risks. Each risk can be described across four dimensions: \u003cstrong\u003eEntity\u003c/strong\u003e, \u003cstrong\u003eIntent\u003c/strong\u003e, \u003cstrong\u003eTiming\u003c/strong\u003e and \u003cstrong\u003eSeverity\u003c/strong\u003e. Patterns aggregate common combinations of these dimensions to highlight strategic mitigation priorities.\u003c/p\u003e\u003ch4\u003e\ud83d\udcca Pattern Taxonomy\u003c/h4\u003e\u003cp\u003eThe heuristic analysis groups risks into distinct pattern categories with examples:\u003c/p\u003e\u003cdiv class=\u0027pattern-category\u0027\u003e\u003ch5\u003e\ud83d\udd34 Critical Patterns\u003c/h5\u003e\u003cp\u003eHigh priority scenarios requiring immediate attention.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eCritical AI\u003c/strong\u003e \u2014 High-severity risks caused by operational AI\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMalicious Human\u003c/strong\u003e \u2014 Deliberate harmful actions by humans\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eAI Failures\u003c/strong\u003e \u2014 Unintentional malfunctions of deployed AI\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cdiv class=\u0027pattern-category\u0027\u003e\u003ch5\u003e\ud83d\udfe1 Moderate Patterns\u003c/h5\u003e\u003cp\u003eMedium priority scenarios that need monitoring.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eMod. Operational\u003c/strong\u003e \u2014 Medium-severity operational risks\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMod. Human\u003c/strong\u003e \u2014 Human-caused medium severity risks\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cdiv class=\u0027pattern-category\u0027\u003e\u003ch5\u003e\ud83d\udfe2 Prevention Patterns\u003c/h5\u003e\u003cp\u003eRisks preventable before deployment.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003ePreventable AI\u003c/strong\u003e \u2014 AI risks detectable in pre-deployment\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePreventable Human\u003c/strong\u003e \u2014 Human errors mitigable by design or training\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cdiv class=\u0027pattern-category\u0027\u003e\u003ch5\u003e\ud83d\udd35 Low Patterns\u003c/h5\u003e\u003cp\u003eLow-priority scenarios for passive monitoring.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cstrong\u003eLow Operational\u003c/strong\u003e \u2014 Minor operational risks with negligible impact\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003cp style=\u0027margin-top:20px;padding:15px;background:#FEF3C7;border-left:4px solid #F59E0B;border-radius:6px;\u0027\u003e\ud83d\udca1 \u003cstrong\u003eHow to read the matrix\u003c/strong\u003e: each cell represents an intersection between a category and a pattern; color intensity encodes frequency.\u003c/p\u003e", "pattern_intentional_ai_risks": "Intentional AI", "pattern_low_operational_risks": "Low Operational", "pattern_low_priority_preventable": "Low Priority Prev.", "pattern_malicious_human_risks": "Malicious Human", "pattern_matrix": "Pattern Matrix", "pattern_moderate_ai_risks": "Mod. AI", "pattern_moderate_human_intentional_risks": "Mod. Intent. Human", "pattern_moderate_human_risks": "Mod. Human", "pattern_moderate_intentional_ai_risks": "Mod. Intent. AI", "pattern_moderate_operational_risks": "Mod. Operational", "pattern_preventable_ai_risks": "Preventable AI", "pattern_preventable_critical_ai_risks": "Prev. Critical AI", "pattern_preventable_human_risks": "Preventable Human", "pattern_preventable_intentional_threats": "Prev. Intent. Threats", "pattern_type_label": "Pattern Type", "pattern_unintended_ai_failures": "AI Failures", "preventability": "Preventability", "preventability_description": " \u2014 % pre-deployment risks. High values (\u003e60%) = preventable/controllable system.", "prevention_deficit": "Prevention Deficit", "prevention_deficit_description": "\u2014 % non-preventable risks. High values (\u003e90%) = low preventive maturity.", "question_label": "Question:", "report_download_button": "Download Report", "risk_concentration": "Risk Concentration", "risk_concentration_description": "\u2014 % HIGH risks. High values (\u003e40%) = critical concentration of severe threats.", "risk_distribution": "Risk Distribution", "risk_severity": {"high": "HIGH", "low": "LOW", "medium": "MEDIUM"}, "risks_count_label": "({{count}} risks)", "risks_identified": "Risks Identified", "safety": "Safety Profile", "safety_culture": "Safety Culture", "safety_culture_description": "\u2014 % unintentional risks. High values (\u003e70%) = fragile but not under attack system.", "sankey_guide_toggle": "Show/Hide Guide", "sankey_info_html": "\u003cp\u003eThe \u003cstrong\u003eCausality Flow diagram\u003c/strong\u003e visualizes causal chains by showing how risks flow across three dimensions: \u003cstrong\u003eEntity\u003c/strong\u003e \u2192 \u003cstrong\u003eIntent\u003c/strong\u003e \u2192 \u003cstrong\u003eTiming\u003c/strong\u003e. Band widths are proportional to the number of risks following each path.\u003c/p\u003e\u003ch5\u003e\ud83d\udd35 Entity\u003c/h5\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eAI\u003c/strong\u003e \u2014 Risks caused by AI systems\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eHuman\u003c/strong\u003e \u2014 Risks originating from human actors\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eOther\u003c/strong\u003e \u2014 Mixed or unclassified origin\u003c/div\u003e\u003ch5\u003e\ud83d\udfe1 Intent\u003c/h5\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eIntentional\u003c/strong\u003e \u2014 Deliberate harmful actions\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eUnintentional\u003c/strong\u003e \u2014 Errors, malfunctions, or unintended consequences\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eOther\u003c/strong\u003e \u2014 Unclassifiable intent\u003c/div\u003e\u003ch5\u003e\u26ab Timing\u003c/h5\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003ePre-deployment\u003c/strong\u003e \u2014 Risks preventable before release\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003ePost-deployment\u003c/strong\u003e \u2014 Risks that manifest in production\u003c/div\u003e\u003cdiv class=\u0027sankey-dimension\u0027\u003e\u003cstrong\u003eOther\u003c/strong\u003e \u2014 Unclassifiable timing\u003c/div\u003e\u003cp style=\u0027margin-top:20px;padding:15px;background:#F3F4F6;border-left:4px solid #6B7280;border-radius:6px;\u0027\u003e\ud83d\udca1 \u003cstrong\u003eHow to read\u003c/strong\u003e: follow flows left to right; wider bands indicate more frequent causal paths.\u003c/p\u003e", "severity_rationale_label": "Severity Rationale:", "subdomains_label": "({{count}} subdomains)", "threat_intensity": "Threat Intensity", "threat_intensity_description": "\u2014 % intentional risks. High values = presence of malicious actors.", "timing_other": "Other Timing", "timing_phase": "Timing Phase", "timing_post_deployment": "Post-deployment", "timing_pre_deployment": "Pre-deployment", "unknown_label": "Unknown", "view_source": "View Analysis Source", "zip_error_alert": "Unable to create ZIP file. Check console for details.", "zip_error_console": "Error creating ZIP:"};
// Charts Configuration - Plotly visualizations

// 1. Risk Distribution by Domain (Stacked Bar Chart)
// Map domain acronyms (D1..D7) to localized full names using translations (d1_title..d7_title)
const mappedDomainNames = chartData.risk_distribution.domains.map((d, i) => {
    const id = d.replace(/^D/i, '');
    return translations['d' + id + '_title'] || chartData.risk_distribution.domain_names[i];
});

const riskDistData = [
    {
        x: chartData.risk_distribution.domains,
        y: chartData.risk_distribution.high,
        name: translations.high || 'HIGH',
        type: 'bar',
        marker: {color: '#DC2626'},
        customdata: mappedDomainNames,
        hovertemplate: '<b>%{customdata}</b><br>' + (translations.high || 'HIGH') + ': %{y}<extra></extra>'
    },
    {
        x: chartData.risk_distribution.domains,
        y: chartData.risk_distribution.medium,
        name: translations.medium || 'MEDIUM',
        type: 'bar',
        marker: {color: '#F59E0B'},
        customdata: mappedDomainNames,
        hovertemplate: '<b>%{customdata}</b><br>' + (translations.medium || 'MEDIUM') + ': %{y}<extra></extra>'
    },
    {
        x: chartData.risk_distribution.domains,
        y: chartData.risk_distribution.low,
        name: translations.low || 'LOW',
        type: 'bar',
        marker: {color: '#10B981'},
        customdata: mappedDomainNames,
        hovertemplate: '<b>%{customdata}</b><br>' + (translations.low || 'LOW') + ': %{y}<extra></extra>'
    }
];

const riskDistLayout = {
    barmode: 'stack',
    xaxis: {
        title: translations.domains || 'Domains'
    },
    yaxis: {
        title: translations.chart_risks_label || 'Number of Risks',
        gridcolor: '#E5E7EB'
    },
    margin: {l: 60, r: 40, t: 60, b: 80},
    plot_bgcolor: '#FAFAFA',
    paper_bgcolor: 'white',
    font: {family: 'inherit', size: 12},
    showlegend: false
};

Plotly.newPlot('risk-distribution-chart', riskDistData, riskDistLayout, {responsive: true});

// 2. Alert Criticality Radar Chart (Dual Profile: Criticality + Safety)
// Convert categorical labels to numeric theta (degrees), build a common axis set
const _mapCritical = {
    'Risk Concentration': translations.risk_concentration || 'Risk Concentration',
    'Operational Exposure': translations.operational_exposure || 'Operational Exposure',
    'Threat Intensity': translations.threat_intensity || 'Threat Intensity',
    'Prevention Deficit': translations.prevention_deficit || 'Prevention Deficit'
};
const _mapSafety = {
    'Impact Control': translations.impact_control || 'Impact Control',
    'Preventability': translations.preventability || 'Preventability',
    'Safety Culture': translations.safety_culture || 'Safety Culture',
    'Human Oversight': translations.human_oversight || 'Human Oversight'
};

const criticalLabels = chartData.alert_criticality.labels.map(l => _mapCritical[l] || l);
const safetyLabels = chartData.alert_criticality.safety_labels.map(l => _mapSafety[l] || l);

// Unified label set (preserve order, avoid duplicates)
const unifiedLabels = [];
[...criticalLabels, ...safetyLabels].forEach(l => { if (unifiedLabels.indexOf(l) === -1) unifiedLabels.push(l); });
const Naxes = unifiedLabels.length || 1;
const thetaVals = unifiedLabels.map((_, i) => i * 360 / Naxes);

function alignValues(sourceLabels, sourceValues) {
    const map = {};
    if (Array.isArray(sourceLabels) && Array.isArray(sourceValues)) {
        sourceLabels.forEach((lab, idx) => { map[lab] = sourceValues[idx] != null ? sourceValues[idx] : 0; });
    }
    return unifiedLabels.map(l => map[l] != null ? map[l] : 0);
}

const criticalR = alignValues(criticalLabels, chartData.alert_criticality.criticality_values);
const safetyR = alignValues(safetyLabels, chartData.alert_criticality.safety_values);

const alertRadarData = [
    {
        type: 'scatterpolar',
        r: criticalR,
        theta: thetaVals,
        text: unifiedLabels,
        fill: 'toself',
        fillcolor: 'rgba(239, 68, 68, 0.35)',
        line: { color: 'rgba(0,0,0,0)', width: 0 },
        marker: { color: '#DC2626', size: 0 },
        name: translations.criticality || 'Alert Criticality',
        hovertemplate: '<b>%{text}</b><br>%{r:.1f}%<extra>' + (translations.criticality || 'Alert Criticality') + '</extra>'
    },
    {
        type: 'scatterpolar',
        r: safetyR,
        theta: thetaVals,
        text: unifiedLabels,
        fill: 'toself',
        fillcolor: 'rgba(16, 185, 129, 0.35)',
        line: { color: 'rgba(0,0,0,0)', width: 0 },
        marker: { color: '#10B981', size: 0 },
        name: translations.safety || 'System Safety',
        hovertemplate: '<b>%{text}</b><br>%{r:.1f}%<extra>' + (translations.safety || 'System Safety') + '</extra>'
    }
];

const alertRadarLayout = {
    polar: {
        radialaxis: {
            visible: true,
            range: [0, 100],
            gridcolor: '#E5E7EB',
            ticksuffix: '%',
            tickfont: {size: 10}
        },
        angularaxis: {
            gridcolor: '#E5E7EB',
            tickfont: {size: 11},
            tickmode: 'array',
            tickvals: thetaVals,
            ticktext: unifiedLabels
        }
    },
    plot_bgcolor: 'white',
    paper_bgcolor: 'white',
    font: {family: 'inherit', size: 11},
    showlegend: true,
    legend: {
        x: 0.5,
        y: -0.15,
        xanchor: 'center',
        yanchor: 'top',
        orientation: 'h',
        bgcolor: 'rgba(255, 255, 255, 0.8)',
        bordercolor: '#E5E7EB',
        borderwidth: 1
    },
    margin: {l: 80, r: 80, t: 40, b: 100}
};

Plotly.newPlot('alert-criticality-chart', alertRadarData, alertRadarLayout, {responsive: true});

// 4. Causality Flow Sankey Diagram
const sankeyData = [{
    type: 'sankey',
    orientation: 'h',
    node: {
        pad: 15,
        thickness: 20,
        line: {
            color: 'white',
            width: 1
        },
        label: chartData.causality_sankey.nodes.map(n => {
            const map = {
                'AI': translations.entity_ai || 'AI',
                'Human': translations.entity_human || 'Human',
                'Other': translations.entity_other || 'Other',
                'Intentional': translations.intent_intentional || 'Intentional',
                'Unintentional': translations.intent_unintentional || 'Unintentional',
                'Other Intent': translations.intent_other || 'Other Intent',
                'Pre-deployment': translations.timing_pre_deployment || 'Pre-deployment',
                'Post-deployment': translations.timing_post_deployment || 'Post-deployment',
                'Other Timing': translations.timing_other || 'Other Timing'
            };
            return map[n] || n;
        }),
        color: [
            '#3B82F6', '#3B82F6', '#94A3B8',  // Entity: blue tones
            '#F59E0B', '#F59E0B', '#94A3B8',  // Intent: amber tones
            '#14B8A6', '#DC2626', '#94A3B8'   // Timing: teal (pre), red (post), gray (other)
        ],
        customdata: chartData.causality_sankey.nodes.map((node, i) => {
            if (i <= 2) return translations.causality_entity_label || 'Entity';
            if (i <= 5) return translations.causality_intent_label || 'Intent';
            return translations.causality_timing_label || 'Timing';
        }),
        hovertemplate: '<b>%{label}</b><br>' + (translations.category_label || 'Category') + ': %{customdata}<br>' + (translations.chart_risks_label || 'Risks') + ': %{value:d}<extra></extra>'
    },
    link: {
        source: chartData.causality_sankey.sources,
        target: chartData.causality_sankey.targets,
        value: chartData.causality_sankey.values.map(v => Math.round(v)),
        color: 'rgba(0,0,0,0.2)',
        hovertemplate: '%{source.label} ‚Üí %{target.label}<br>' + (translations.chart_risks_label || 'Risks') + ': %{value:d}<extra></extra>'
    }
}];

const sankeyLayout = {
    font: {family: 'inherit', size: 12},
    plot_bgcolor: 'white',
    paper_bgcolor: 'white',
    margin: {l: 10, r: 10, t: 10, b: 10}
};

Plotly.newPlot('causality-sankey-chart', sankeyData, sankeyLayout, {responsive: true});

// 3. Patterns Heatmap
const heatmapData = [{
    z: chartData.patterns_heatmap.values,
    x: chartData.patterns_heatmap.patterns,
    y: chartData.patterns_heatmap.categories,
    type: 'heatmap',
    colorscale: [
        [0, '#EFF6FF'],
        [0.3, '#BFDBFE'],
        [0.6, '#60A5FA'],
        [1, '#1E40AF']
    ],
    hovertemplate: '<b>%{y}</b><br>%{x}<br>' + (translations.chart_risks_label || 'Risks') + ': %{z}<extra></extra>',
    colorbar: {
        title: translations.chart_risks_label || 'Risks',
        titleside: 'right',
        tickmode: 'linear',
        tick0: 0
    }
}];

const heatmapLayout = {
    xaxis: {
        title: translations.pattern_type_label || 'Pattern Type',
        tickangle: -45,
        automargin: true
    },
    yaxis: {
        title: translations.category_label || 'Category',
        automargin: true
    },
    margin: {l: 120, r: 100, t: 80, b: 150},
    plot_bgcolor: 'white',
    paper_bgcolor: 'white',
    font: {family: 'inherit', size: 11}
};

Plotly.newPlot('patterns-heatmap', heatmapData, heatmapLayout, {responsive: true});

// Navigation - Toggle functions for hierarchical tree

function toggleDomain(header) {
    const content = header.nextElementSibling;
    const isCollapsed = header.classList.contains('collapsed');
    
    if (isCollapsed) {
        header.classList.remove('collapsed');
        content.style.display = 'block';
    } else {
        header.classList.add('collapsed');
        content.style.display = 'none';
    }
}

function togglePatternInfo() {
    const infoBox = document.getElementById('pattern-info');
    infoBox.classList.toggle('collapsed');
}

function toggleDomainInfo() {
    const infoBox = document.getElementById('domain-info');
    infoBox.classList.toggle('collapsed');
}

function toggleAlertInfo() {
    const infoBox = document.getElementById('alert-info');
    infoBox.classList.toggle('collapsed');
}

function toggleSankeyInfo() {
    const infoBox = document.getElementById('sankey-info');
    infoBox.classList.toggle('collapsed');
}

function toggleSubdomain(header) {
    const content = header.nextElementSibling;
    const isCollapsed = header.classList.contains('collapsed');
    
    if (isCollapsed) {
        header.classList.remove('collapsed');
        content.style.display = 'block';
    } else {
        header.classList.add('collapsed');
        content.style.display = 'none';
    }
}

function toggleRiskDetails(item) {
    const details = item.querySelector('.risk-details');
    details.classList.toggle('expanded');
}

// Filters - Apply filters to risk table

function applyFilters() {
    const severityFilter = document.getElementById('severity-filter').value;
    const entityFilter = document.getElementById('entity-filter').value;
    const timingFilter = document.getElementById('timing-filter').value;
    const intentFilter = document.getElementById('intent-filter').value;
    
    const riskItems = document.querySelectorAll('.risk-item');
    
    riskItems.forEach(item => {
        const severity = item.dataset.severity;
        const entity = item.dataset.entity;
        const timing = item.dataset.timing;
        const intent = item.dataset.intent;
        
        const severityMatch = severityFilter === 'all' || severity === severityFilter;
        const entityMatch = entityFilter === 'all' || entity === entityFilter;
        const timingMatch = timingFilter === 'all' || timing === timingFilter;
        const intentMatch = intentFilter === 'all' || intent === intentFilter;
        
        if (severityMatch && entityMatch && timingMatch && intentMatch) {
            item.style.display = 'block';
        } else {
            item.style.display = 'none';
        }
    });
    
    updateVisibility();
}

function updateVisibility() {
    // Check subdomains
    document.querySelectorAll('.subdomain-block').forEach(subdomain => {
        const visibleRisks = subdomain.querySelectorAll('.risk-item[style="display: block;"], .risk-item:not([style*="display: none"])');
        if (visibleRisks.length === 0) {
            subdomain.style.display = 'none';
        } else {
            subdomain.style.display = 'block';
        }
    });
    
    // Check domains
    document.querySelectorAll('.domain-block').forEach(domain => {
        const visibleSubdomains = domain.querySelectorAll('.subdomain-block[style="display: block;"], .subdomain-block:not([style*="display: none"])');
        if (visibleSubdomains.length === 0) {
            domain.style.display = 'none';
        } else {
            domain.style.display = 'block';
        }
    });
}

    </script>
    <script>
        function handleDownloadClick() {
            if (typeof window.createReportZip === 'function') {
                try {
                    window.createReportZip();
                } catch (e) {
                    console.error('Error creating ZIP:', e);
                    alert('Unable to create ZIP file. Check console for details.');
                }
            } else {
                alert('Report offline: on-demand download not available. Open the report from a server or include report_download.js to enable downloads.');
            }
        }
    </script>
    <script src="scripts/report_download.js"></script>
</body>
</html>